{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg8ZpA55yywi",
        "outputId": "a14f5fcb-6472-4428-e8ee-823c8417cc80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import openai\n",
        "from google.colab import drive\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "################################################################################\n",
        "# 1) Mount Google Drive\n",
        "################################################################################\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "################################################################################\n",
        "# 2) Set API Keys\n",
        "################################################################################\n",
        "PINECONE_API_KEY = \"YOUR-PINECONE-API-KEY\"\n",
        "PINECONE_REGION  = \"us-east-1\"\n",
        "OPENAI_API_KEY   = \"YOUR-OPENAI-API-KEY\"\n",
        "\n",
        "INDEX_NAME = \"PINECONE-INDEX-NAME\"        # your Pinecone index name\n",
        "EMBED_MODEL = \"text-embedding-3-large\"  # using '3-large' with ~8k context\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "################################################################################\n",
        "# 3) Initialize Pinecone (New Approach)\n",
        "################################################################################\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_REGION)\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=3072,            # same dimension as 'text-embedding-3-large'\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_REGION)\n",
        "    )\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "################################################################################\n",
        "# 4) Utility Functions\n",
        "################################################################################\n",
        "\n",
        "def sanitize_vector_id(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove non-ASCII characters from text to produce a safe vector ID.\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "def chunk_text_by_tokens(text: str, chunk_size: int = 6000, model_name: str = EMBED_MODEL) -> list:\n",
        "    \"\"\"\n",
        "    Splits 'text' into chunks of up to 'chunk_size' tokens each,\n",
        "    using the specified 'model_name' for tokenization (via tiktoken).\n",
        "    \"\"\"\n",
        "    import tiktoken\n",
        "\n",
        "    try:\n",
        "        enc = tiktoken.encoding_for_model(model_name)\n",
        "    except KeyError:\n",
        "        # If for some reason tiktoken doesn't recognize the model, default to cl100k_base\n",
        "        enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    tokens = enc.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), chunk_size):\n",
        "        chunk_tokens = tokens[i:i+chunk_size]\n",
        "        chunk_text = enc.decode(chunk_tokens)\n",
        "        chunks.append(chunk_text)\n",
        "    return chunks\n",
        "\n",
        "def call_with_rate_limit_handling(func, *args, max_retries=5, **kwargs):\n",
        "    \"\"\"\n",
        "    General purpose function to call any API with rate limit handling.\n",
        "\n",
        "    Args:\n",
        "        func: The function to call\n",
        "        max_retries: Maximum number of retries before giving up\n",
        "        *args, **kwargs: Arguments to pass to func\n",
        "\n",
        "    Returns:\n",
        "        The result of the function call, or None if all retries failed\n",
        "    \"\"\"\n",
        "    retry_count = 0\n",
        "    base_wait = 2  # Start with a 2 second wait\n",
        "\n",
        "    while retry_count <= max_retries:\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            retry_count += 1\n",
        "            error_str = str(e)\n",
        "\n",
        "            # Check if it's a rate limit error\n",
        "            if \"429\" in error_str or \"rate limit\" in error_str.lower():\n",
        "                # Exponential backoff with jitter\n",
        "                wait_time = base_wait * (2 ** retry_count) + (retry_count * 0.1)\n",
        "                print(f\"Rate limited. Waiting {wait_time:.1f} seconds before retry {retry_count}/{max_retries}...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"Error calling {func.__name__}: {e}\")\n",
        "                if retry_count >= max_retries:\n",
        "                    print(f\"Max retries reached.\")\n",
        "                    return None\n",
        "                print(f\"Retrying in 2 seconds...\")\n",
        "                time.sleep(2)\n",
        "\n",
        "    return None\n",
        "\n",
        "def generate_title_from_json(json_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses a large language model to generate a concise, descriptive title from the JSON content.\n",
        "    The title will be in lowercase and use underscores, e.g. \"agent_google_sheet_slack\".\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are given a JSON representation of an automation workflow.\n",
        "Generate a concise, descriptive, and uniform title that captures the automation's main functionality.\n",
        "The title should be in lowercase and use underscores to separate words.\n",
        "For example, if the automation reads from Google Sheets, calls an LLM, and sends a message to Slack,\n",
        "you might return: agent_google_sheet_slack.\n",
        "Only output the title.\n",
        "\n",
        "JSON Content:\n",
        "{json_text}\n",
        "    \"\"\"\n",
        "\n",
        "    def _generate_title():\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\", # Removed reasoning_effort\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    try:\n",
        "        return call_with_rate_limit_handling(_generate_title)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating title: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_tldr_from_json(json_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Uses a large language model to generate a one-sentence TLDR summary of the automation.\n",
        "    This summary describes the core functionality in plain language.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are given a JSON representation of an automation workflow.\n",
        "Generate a concise one-sentence summary (TLDR) of what this automation does.\n",
        "It should capture the core functionality in plain language.\n",
        "Only output the summary.\n",
        "\n",
        "JSON Content:\n",
        "{json_text}\n",
        "    \"\"\"\n",
        "\n",
        "    def _generate_tldr():\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\", # Removed reasoning_effort\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    try:\n",
        "        return call_with_rate_limit_handling(_generate_tldr)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating TLDR: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_embeddings(text):\n",
        "    \"\"\"Create embeddings with rate limit handling\"\"\"\n",
        "    def _embed():\n",
        "        response = openai.embeddings.create(\n",
        "            input=[text],\n",
        "            model=EMBED_MODEL\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "\n",
        "    return call_with_rate_limit_handling(_embed)\n",
        "\n",
        "################################################################################\n",
        "# 5) Process Files with Checkpointing and Batch Processing\n",
        "################################################################################\n",
        "\n",
        "def main():\n",
        "    folder_path = \"/content/drive/MyDrive/n8n Workflows\"  # Adjust if needed\n",
        "    checkpoint_file = os.path.join(folder_path, \"processing_checkpoint.json\")\n",
        "\n",
        "    # Load checkpoint if exists\n",
        "    processed_files = []\n",
        "    current_batch = 0\n",
        "    batch_size = 5  # Process files in small batches to avoid rate limits\n",
        "\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        try:\n",
        "            with open(checkpoint_file, 'r') as f:\n",
        "                checkpoint_data = json.load(f)\n",
        "                processed_files = checkpoint_data.get('processed_files', [])\n",
        "                current_batch = checkpoint_data.get('current_batch', 0)\n",
        "                print(f\"Resuming from checkpoint: {len(processed_files)} files processed, batch {current_batch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "\n",
        "    # Get all files to process\n",
        "    all_files = [f for f in os.listdir(folder_path)\n",
        "                if (f.lower().endswith(\".txt\") or f.lower().endswith(\".json\"))\n",
        "                and f != \"processing_checkpoint.json\"]\n",
        "\n",
        "    # Skip already processed files\n",
        "    remaining_files = [f for f in all_files if f not in processed_files]\n",
        "    print(f\"Total files: {len(all_files)}, Remaining: {len(remaining_files)}\")\n",
        "\n",
        "    try:\n",
        "        # Process files in batches\n",
        "        batches = [remaining_files[i:i + batch_size] for i in range(0, len(remaining_files), batch_size)]\n",
        "\n",
        "        if not batches:  # Handle case when all files are processed\n",
        "            print(\"All files have already been processed!\")\n",
        "            return\n",
        "\n",
        "        for batch_idx, batch in enumerate(batches[current_batch:], current_batch):\n",
        "            print(f\"\\n--- Processing Batch {batch_idx + 1}/{len(batches)} ---\")\n",
        "\n",
        "            for file_name in batch:\n",
        "                print(f\"\\nProcessing file: {file_name}\")\n",
        "                full_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "                try:\n",
        "                    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                        file_text = f.read()\n",
        "\n",
        "                    # Generate a descriptive title\n",
        "                    generated_title = generate_title_from_json(file_text)\n",
        "                    if generated_title:\n",
        "                        base_vector_id = sanitize_vector_id(generated_title)\n",
        "                        print(f\"Generated title: {generated_title} (vector base ID: {base_vector_id})\")\n",
        "                    else:\n",
        "                        base_vector_id = sanitize_vector_id(file_name)\n",
        "                        generated_title = file_name\n",
        "                        print(f\"Using fallback title: {generated_title} (vector base ID: {base_vector_id})\")\n",
        "\n",
        "                    # Generate a TLDR (agent summary)\n",
        "                    generated_tldr = generate_tldr_from_json(file_text)\n",
        "                    if generated_tldr:\n",
        "                        print(f\"Generated TLDR: {generated_tldr}\")\n",
        "                    else:\n",
        "                        generated_tldr = \"\"\n",
        "                        print(f\"Using empty TLDR.\")\n",
        "\n",
        "                    # Token-based chunking\n",
        "                    chunks = chunk_text_by_tokens(file_text, chunk_size=6000, model_name=EMBED_MODEL)\n",
        "                    print(f\"Processing {len(chunks)} chunk(s).\")\n",
        "\n",
        "                    # Process each chunk with rate limit handling\n",
        "                    for idx, chunk in enumerate(chunks):\n",
        "                        vector_id = base_vector_id if len(chunks) == 1 else f\"{base_vector_id}_{idx}\"\n",
        "\n",
        "                        # Create embeddings\n",
        "                        embedding = create_embeddings(chunk)\n",
        "                        if embedding is None:\n",
        "                            print(f\"Failed to create embedding for chunk {idx}. Skipping.\")\n",
        "                            continue\n",
        "\n",
        "                        # Create metadata\n",
        "                        metadata = {\n",
        "                            \"generated_title\": generated_title,\n",
        "                            \"agent_summary\": generated_tldr,\n",
        "                            \"chunk_index\": idx,\n",
        "                            \"json_file\": chunk\n",
        "                        }\n",
        "\n",
        "                        # Insert into Pinecone\n",
        "                        def upsert_to_pinecone():\n",
        "                            index.upsert(vectors=[(vector_id, embedding, metadata)])\n",
        "                            return True\n",
        "\n",
        "                        success = call_with_rate_limit_handling(upsert_to_pinecone)\n",
        "                        if success:\n",
        "                            print(f\"Upserted chunk {idx} as vector ID '{vector_id}'.\")\n",
        "                        else:\n",
        "                            print(f\"Failed to upsert chunk {idx}.\")\n",
        "\n",
        "                    # Add file to processed list\n",
        "                    processed_files.append(file_name)\n",
        "\n",
        "                    # Update checkpoint after each file\n",
        "                    with open(checkpoint_file, 'w') as f:\n",
        "                        checkpoint_data = {\n",
        "                            'processed_files': processed_files,\n",
        "                            'current_batch': batch_idx\n",
        "                        }\n",
        "                        json.dump(checkpoint_data, f)\n",
        "\n",
        "                    # Small pause between files to avoid rate limits\n",
        "                    time.sleep(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing file '{file_name}': {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Update batch in checkpoint\n",
        "            with open(checkpoint_file, 'w') as f:\n",
        "                checkpoint_data = {\n",
        "                    'processed_files': processed_files,\n",
        "                    'current_batch': batch_idx + 1\n",
        "                }\n",
        "                json.dump(checkpoint_data, f)\n",
        "\n",
        "            # Pause between batches\n",
        "            if batch_idx < len(batches) - 1:\n",
        "                print(f\"Batch {batch_idx + 1} complete. Pausing for 10 seconds before next batch...\")\n",
        "                time.sleep(10)\n",
        "\n",
        "        print(\"\\nAll files processed successfully!\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user.\")\n",
        "        print(f\"Progress saved. You can resume from where you left off.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nUnexpected error: {e}\")\n",
        "        print(f\"Progress saved. You can resume from where you left off.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD5DQgQcyz0A",
        "outputId": "70761d0c-5b31-4171-9d32-ce1dc3051652"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total files: 293, Remaining: 293\n",
            "\n",
            "--- Processing Batch 1/59 ---\n",
            "\n",
            "Processing file: Create dynamic Twitter profile banner.txt\n",
            "Generated title: fetch_twitter_followers_profile_image_processing (vector base ID: fetch_twitter_followers_profile_image_processing)\n",
            "Generated TLDR: This automation workflow fetches new followers from Twitter, resizes and crops their profile images, merges them into a composite image, and updates the user's profile banner.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'fetch_twitter_followers_profile_image_processing'.\n",
            "\n",
            "Processing file: Send specific PDF attachments from Gmail to Google Drive using OpenAI.txt\n",
            "Generated title: pdf_gmail_drive_openai_workflow (vector base ID: pdf_gmail_drive_openai_workflow)\n",
            "Generated TLDR: This automation workflow reads PDF content from Gmail attachments, uses OpenAI to match specified criteria, and uploads matching PDFs to Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'pdf_gmail_drive_openai_workflow'.\n",
            "\n",
            "Processing file: Detect toxic language in Telegram messages.txt\n",
            "Generated title: detect_toxic_language_telegram_messages (vector base ID: detect_toxic_language_telegram_messages)\n",
            "Generated TLDR: Detect toxic language in Telegram messages.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'detect_toxic_language_telegram_messages'.\n",
            "\n",
            "Processing file: Reddit AI digest.txt\n",
            "Generated title: reddit_n8n_classification_workflow. (vector base ID: reddit_n8n_classification_workflow.)\n",
            "Generated TLDR: This automation workflow retrieves and categorizes Reddit posts related to \"n8n\" using OpenAI for summarization.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'reddit_n8n_classification_workflow.'.\n",
            "\n",
            "Processing file: Summarize Google Sheets form feedback via OpenAI_s GPT-4.txt\n",
            "Generated title: summarize_google_sheets_form_feedback_via_openai_gpt_4 (vector base ID: summarize_google_sheets_form_feedback_via_openai_gpt_4)\n",
            "Generated TLDR: This automation summarizes Google Sheets form feedback using OpenAI's GPT-4 model and sends a report via Gmail.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'summarize_google_sheets_form_feedback_via_openai_gpt_4'.\n",
            "Batch 1 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 2/59 ---\n",
            "\n",
            "Processing file: OpenAI-powered tweet generator.txt\n",
            "Generated title: manualtrigger_functionitem_http_request_airtable_set (vector base ID: manualtrigger_functionitem_http_request_airtable_set)\n",
            "Generated TLDR: This automation generates and tweets a short text using a random hashtag and saves it to an Airtable database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'manualtrigger_functionitem_http_request_airtable_set'.\n",
            "\n",
            "Processing file: Configure your own Image Creation API Using OpenAI DALLE-3.txt\n",
            "Generated title: image_generation_api (vector base ID: image_generation_api)\n",
            "Generated TLDR: This automation workflow generates images using OpenAI in response to webhook requests.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'image_generation_api'.\n",
            "\n",
            "Processing file: lemlist __ GPT-3_ Supercharge your sales workflows.txt\n",
            "Generated title: lemlist_gpt3_supercharge_sales_workflows (vector base ID: lemlist_gpt3_supercharge_sales_workflows)\n",
            "Generated TLDR: This automation workflow manages leads, categorizes responses, and triggers follow-up actions efficiently.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'lemlist_gpt3_supercharge_sales_workflows'.\n",
            "\n",
            "Processing file: Custom LangChain agent written in JavaScript.txt\n",
            "Generated title: llm_chain_on_agent (vector base ID: llm_chain_on_agent)\n",
            "Generated TLDR: This automation workflow generates responses using AI language models based on user prompts.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'llm_chain_on_agent'.\n",
            "\n",
            "Processing file: AI_ Ask questions about any data source (using the n8n workflow retriever).txt\n",
            "Generated title: execute_workflow_retriever_chat_model (vector base ID: execute_workflow_retriever_chat_model)\n",
            "Generated TLDR: This automation workflow retrieves data based on a specified workflow ID and prompts for related information using an OpenAI chat model.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'execute_workflow_retriever_chat_model'.\n",
            "Batch 2 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 3/59 ---\n",
            "\n",
            "Processing file: Classify lemlist replies using OpenAI and automate reply handling.txt\n",
            "Generated title: send_reply_classification_slack (vector base ID: send_reply_classification_slack)\n",
            "Generated TLDR: This automation workflow categorizes and routes replies from lemlist campaigns using OpenAI and sends notifications to Slack based on the reply status.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'send_reply_classification_slack'.\n",
            "\n",
            "Processing file: ðŸ¤–ðŸ§‘_ðŸ’» AI Agent for Top n8n Creators Leaderboard Reporting.txt\n",
            "Generated title: n8n_creators_leaderboard_reporting_workflow (vector base ID: n8n_creators_leaderboard_reporting_workflow)\n",
            "Generated TLDR: This automation workflow generates a comprehensive report on the top n8n creators and workflows using data aggregation and AI tools.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'n8n_creators_leaderboard_reporting_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'n8n_creators_leaderboard_reporting_workflow_1'.\n",
            "\n",
            "Processing file: Enrich Pipedrive_s Organization Data with OpenAI GPT-4o & Notify it in Slack.txt\n",
            "Generated title: enrich_pipedrive_organization_data (vector base ID: enrich_pipedrive_organization_data)\n",
            "Generated TLDR: This automation enriches Pipedrive's organization data by adding a note with content generated by GPT-4o when a new organization is created in Pipedrive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'enrich_pipedrive_organization_data'.\n",
            "\n",
            "Processing file: Update Twitter banner using HTTP request.txt\n",
            "Generated title: http_request_twitter_update_profile_banner (vector base ID: http_request_twitter_update_profile_banner)\n",
            "Generated TLDR: This automation workflow downloads an image from Unsplash and updates a Twitter profile banner using OAuth authentication.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'http_request_twitter_update_profile_banner'.\n",
            "\n",
            "Processing file: Bitrix24 Chatbot Application Workflow example with Webhook Integration.txt\n",
            "Generated title: bitrix24_chatbot_application_workflow_example_with_webhook_integration (vector base ID: bitrix24_chatbot_application_workflow_example_with_webhook_integration)\n",
            "Generated TLDR: This automation workflow handles Bitrix24 chatbot events and processes messages accordingly.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'bitrix24_chatbot_application_workflow_example_with_webhook_integration'.\n",
            "Batch 3 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 4/59 ---\n",
            "\n",
            "Processing file: OpenAI examples_ ChatGPT, DALLE-2, Whisper-1 â€“ 5-in-1.txt\n",
            "Generated title: openai_model_examples (vector base ID: openai_model_examples)\n",
            "Generated TLDR: This automation workflow utilizes OpenAI models to generate text summaries and translations based on the input provided.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'openai_model_examples'.\n",
            "\n",
            "Processing file: AI Agent with Ollama for current weather and wiki.txt\n",
            "Generated title: ai_agent_weather_tool_wikipedia_fetching (vector base ID: ai_agent_weather_tool_wikipedia_fetching)\n",
            "Generated TLDR: This automation workflow assists a conversational agent in utilizing tools like weather and Wikipedia to provide information based on user messages.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_weather_tool_wikipedia_fetching'.\n",
            "\n",
            "Processing file: AI_ Summarize podcast episode and enhance using Wikipedia.txt\n",
            "Generated title: podcast_digest_workflow_extraction (vector base ID: podcast_digest_workflow_extraction)\n",
            "Generated TLDR: This automation workflow segments and summarizes a podcast episode, generates questions and topics from the summary, researches and explains the topics using Wikipedia, and formats the information into an HTML email for distribution.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'podcast_digest_workflow_extraction_0'.\n",
            "Upserted chunk 1 as vector ID 'podcast_digest_workflow_extraction_1'.\n",
            "\n",
            "Processing file: Venafi Cloud Slack Cert Bot.txt\n",
            "Generated title: venafi_tls_protect_cloud_workflow (vector base ID: venafi_tls_protect_cloud_workflow)\n",
            "Generated TLDR: This automation workflow helps automate the process of issuing SSL certificates based on domain reputation analysis and manual approval, enhancing security operations efficiency.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'venafi_tls_protect_cloud_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'venafi_tls_protect_cloud_workflow_1'.\n",
            "Upserted chunk 2 as vector ID 'venafi_tls_protect_cloud_workflow_2'.\n",
            "\n",
            "Processing file: Chat with your event schedule from Google Sheets in Telegram.txt\n",
            "Generated title: telegram_bot_ai_da_nang (vector base ID: telegram_bot_ai_da_nang)\n",
            "Generated TLDR: This automation workflow processes chat inputs and outputs for scheduling meetups, including retrieving schedule data from a Google Spreadsheet and providing responses for Telegram and n8n chat platforms.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_bot_ai_da_nang'.\n",
            "Batch 4 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 5/59 ---\n",
            "\n",
            "Processing file: Monthly Spotify Track Archiving and Playlist Classification.txt\n",
            "Generated title: spotify_monthly_track_archiving_ai_classification (vector base ID: spotify_monthly_track_archiving_ai_classification)\n",
            "Generated TLDR: This automation workflow archives monthly Spotify tracks, classifies them into playlists using an AI model, and logs the data in Google Sheets.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'spotify_monthly_track_archiving_ai_classification_0'.\n",
            "Upserted chunk 1 as vector ID 'spotify_monthly_track_archiving_ai_classification_1'.\n",
            "Upserted chunk 2 as vector ID 'spotify_monthly_track_archiving_ai_classification_2'.\n",
            "\n",
            "Processing file: Enhance Security Operations with the Qualys Slack Shortcut Bot! (1).txt\n",
            "Generated title: qualys_slack_interaction_handling_with_n8n (vector base ID: qualys_slack_interaction_handling_with_n8n)\n",
            "Generated TLDR: This automation workflow facilitates the initiation of vulnerability scans and generation of detailed reports in Qualys directly through Slack interactions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'qualys_slack_interaction_handling_with_n8n_0'.\n",
            "Upserted chunk 1 as vector ID 'qualys_slack_interaction_handling_with_n8n_1'.\n",
            "\n",
            "Processing file: Summarize SERPBear data with AI (via Openrouter) and save it to Baserow.txt\n",
            "Generated title: get_serpbear_data_ai_baserow (vector base ID: get_serpbear_data_ai_baserow)\n",
            "Generated TLDR: This automation workflow retrieves SEO ranking data from SERPBear, analyzes it using A.I., and saves the results to Baserow.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'get_serpbear_data_ai_baserow'.\n",
            "\n",
            "Processing file: Translate audio using AI.txt\n",
            "Generated title: translate_french_text_to_spoken_audio (vector base ID: translate_french_text_to_spoken_audio)\n",
            "Generated TLDR: This automation translates French text into spoken audio, transcribes it back into text, translates it into English, and generates an audio file of the English text.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'translate_french_text_to_spoken_audio'.\n",
            "\n",
            "Processing file: Post New YouTube Videos to X.txt\n",
            "Generated title: promote_new_youtube_videos_with_ai (vector base ID: promote_new_youtube_videos_with_ai)\n",
            "Generated TLDR: This automation workflow generates engaging Twitter posts promoting the latest YouTube videos for account X using AI and scheduled checks every 30 minutes.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'promote_new_youtube_videos_with_ai'.\n",
            "Batch 5 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 6/59 ---\n",
            "\n",
            "Processing file: Hacker News Job Listing Scraper and Parser.txt\n",
            "Generated title: hn_who_is_hiring_scrape (vector base ID: hn_who_is_hiring_scrape)\n",
            "Generated TLDR: TLDR: This automation workflow scrapes the \"Ask HN: Who is hiring?\" posts from Hacker News, extracts job data, structures it using OpenAI, and writes it to Airtable.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'hn_who_is_hiring_scrape'.\n",
            "\n",
            "Processing file: vAssistant for Hubspot Chat using OpenAi and Airtable.txt\n",
            "Generated title: openai_assistant_for_hubspot_chat (vector base ID: openai_assistant_for_hubspot_chat)\n",
            "Generated TLDR: This automation retrieves messages from Hubspot chat, creates a thread in OpenAI, runs the thread, monitors the status, and responds back to the chat service.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'openai_assistant_for_hubspot_chat_0'.\n",
            "Upserted chunk 1 as vector ID 'openai_assistant_for_hubspot_chat_1'.\n",
            "\n",
            "Processing file: Classify new bugs in Linear with OpenAI_s GPT-4 and move them to the right team.txt\n",
            "Generated title: linear_trigger_classify_bug_team_notification (vector base ID: linear_trigger_classify_bug_team_notification)\n",
            "Generated TLDR: Automatically classifies bug tickets in Linear and assigns them to the appropriate team based on description and labels.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'linear_trigger_classify_bug_team_notification'.\n",
            "\n",
            "Processing file: AI-Powered Children_s Arabic Storytelling on Telegram.txt\n",
            "Generated title: create_story_kids_story_arabic (vector base ID: create_story_kids_story_arabic)\n",
            "Generated TLDR: This automation creates and shares educational stories for kids in Arabic using AI-generated text, images, and audio.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'create_story_kids_story_arabic'.\n",
            "\n",
            "Processing file: Qualify new leads in Google Sheets via OpenAI_s GPT-4.txt\n",
            "Generated title: qualify_leads_google_sheets_gpt (vector base ID: qualify_leads_google_sheets_gpt)\n",
            "Generated TLDR: Qualify new leads in Google Sheets using OpenAI's GPT-4.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'qualify_leads_google_sheets_gpt'.\n",
            "Batch 6 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 7/59 ---\n",
            "\n",
            "Processing file: Discord AI-powered bot.txt\n",
            "Generated title: discord_ai_bot_classification_workflow (vector base ID: discord_ai_bot_classification_workflow)\n",
            "Generated TLDR: TLDR: An automation workflow that categorizes user feedback and directs it to the appropriate departments via Discord based on the analysis results.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'discord_ai_bot_classification_workflow'.\n",
            "\n",
            "Processing file: Automate testimonials in Strapi with n8n.txt\n",
            "Generated title: store_twitter_activity_sentiments_strapi (vector base ID: store_twitter_activity_sentiments_strapi)\n",
            "Generated TLDR: This automation workflow simplifies and stores Twitter content in a Strapi database while analyzing sentiments and filtering positive ones.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'store_twitter_activity_sentiments_strapi'.\n",
            "\n",
            "Processing file: Qualify replies from Pipedrive persons with AI.txt\n",
            "Generated title: search_person_in_crm_campaign_interest_analysis (vector base ID: search_person_in_crm_campaign_interest_analysis)\n",
            "Generated TLDR: This automation workflow reads replies from a cold email campaign and qualifies leads for meetings, creating deals in Pipedrive for interested leads.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'search_person_in_crm_campaign_interest_analysis'.\n",
            "\n",
            "Processing file: Add positive feedback messages to a table in Notion.txt\n",
            "Generated title: typeform_trigger_google_cloud_natural_language_moderation_workflow. (vector base ID: typeform_trigger_google_cloud_natural_language_moderation_workflow.)\n",
            "Generated TLDR: This automation workflow analyzes feedback from a Typeform submission, assesses sentiment using Google Cloud Natural Language, and sends it to Notion, Slack, and Trello based on the sentiment score.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'typeform_trigger_google_cloud_natural_language_moderation_workflow.'.\n",
            "\n",
            "Processing file: Scrape and summarize posts of a news site without RSS feed using AI and save them to a NocoDB.txt\n",
            "Generated title: news_extraction_workflow (vector base ID: news_extraction_workflow)\n",
            "Generated TLDR: This automation workflow extracts and processes the newest news posts from a website, creating summaries and identifying key technical keywords for each post.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'news_extraction_workflow'.\n",
            "Batch 7 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 8/59 ---\n",
            "\n",
            "Processing file: AI Customer feedback sentiment analysis.txt\n",
            "Generated title: send_customer_feedback_to_openai_google_sheet_slack (vector base ID: send_customer_feedback_to_openai_google_sheet_slack)\n",
            "Generated TLDR: This automation workflow captures customer feedback, sends it for sentiment analysis using OpenAI, and adds the results to a Google Sheets document.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'send_customer_feedback_to_openai_google_sheet_slack'.\n",
            "\n",
            "Processing file: Convert text to speech with OpenAI.txt\n",
            "Generated title: text_to_speech_openai_workflow (vector base ID: text_to_speech_openai_workflow)\n",
            "Generated TLDR: This automation workflow converts text into speech using OpenAI's TTS (Text-to-Speech) service.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'text_to_speech_openai_workflow'.\n",
            "\n",
            "Processing file: Analyze feedback using AWS Comprehend and send it to a Mattermost channel.txt\n",
            "Generated title: typeform_trigger_aws_comprehend_if_mattermost (vector base ID: typeform_trigger_aws_comprehend_if_mattermost)\n",
            "Generated TLDR: Automatically sends negative feedback from Typeform to Mattermost using AWS Comprehend for sentiment analysis.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'typeform_trigger_aws_comprehend_if_mattermost'.\n",
            "\n",
            "Processing file: Extract data from resume and create PDF with Gotenberg.txt\n",
            "Generated title: parse_resume_data_conversion_workflow (vector base ID: parse_resume_data_conversion_workflow)\n",
            "Generated TLDR: Parse resume data and create structured HTML output for employment history, education, projects, volunteering, and technologies using OpenAI model.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'parse_resume_data_conversion_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'parse_resume_data_conversion_workflow_1'.\n",
            "\n",
            "Processing file: Ask a human for help when the AI doesn_t know the answer.txt\n",
            "Generated title: window_buffer_memory_ai_agent_chat_trigger_main_workflow_ai_agent_main_workflow_check_user_email_message_slack_help (vector base ID: window_buffer_memory_ai_agent_chat_trigger_main_workflow_ai_agent_main_workflow_check_user_email_message_slack_help)\n",
            "Generated TLDR: This automation workflow uses an AI agent to answer user questions and prompts users to provide an email if needed, messaging a human for assistance if necessary.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'window_buffer_memory_ai_agent_chat_trigger_main_workflow_ai_agent_main_workflow_check_user_email_message_slack_help'.\n",
            "Batch 8 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 9/59 ---\n",
            "\n",
            "Processing file: ETL pipeline for text processing.txt\n",
            "Generated title: etl_pipeline_twitter_nlp_postgres_slack (vector base ID: etl_pipeline_twitter_nlp_postgres_slack)\n",
            "Generated TLDR: This automation workflow fetches tweets with a specific hashtag, analyzes sentiment using Google Cloud Natural Language, and posts them in Slack if sentiment score is above a threshold.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'etl_pipeline_twitter_nlp_postgres_slack'.\n",
            "\n",
            "Processing file: Enhance Security Operations with the Qualys Slack Shortcut Bot!.txt\n",
            "Generated title: route_slack_interaction_handling_workflow (vector base ID: route_slack_interaction_handling_workflow)\n",
            "Generated TLDR: This automation workflow streamlines Slack interactions for initiating vulnerability scans and generating reports through dynamic modal popups.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'route_slack_interaction_handling_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'route_slack_interaction_handling_workflow_1'.\n",
            "\n",
            "Processing file: Send a random recipe once a day to Telegram.txt\n",
            "Generated title: cron_airtable_telegram_recipe_notification (vector base ID: cron_airtable_telegram_recipe_notification)\n",
            "Generated TLDR: This automation sends a random vegan recipe daily to users who join a Telegram bot, storing their chat IDs in an Airtable and checking if it's a new or existing user.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'cron_airtable_telegram_recipe_notification'.\n",
            "\n",
            "Processing file: OpenAI assistant with custom tools.txt\n",
            "Generated title: openai_assistant_custom_n8n_tools. (vector base ID: openai_assistant_custom_n8n_tools.)\n",
            "Generated TLDR: This automation workflow allows users to interact with an OpenAI Assistant to get information about fictional countries and their capitals.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'openai_assistant_custom_n8n_tools.'.\n",
            "\n",
            "Processing file: Automate Screenshots with URLbox & Analyze them with AI.txt\n",
            "Generated title: analyze_screenshots_with_ai (vector base ID: analyze_screenshots_with_ai)\n",
            "Generated TLDR: Automate analyzing website screenshots using URLbox API and OpenAI to extract website content.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'analyze_screenshots_with_ai'.\n",
            "Batch 9 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 10/59 ---\n",
            "\n",
            "Processing file: Compose reply draft in Gmail with OpenAI Assistant.txt\n",
            "Generated title: convert_response_to_html_create_html_message_build_and_encode_message_insert_reply_draft_remove_label (vector base ID: convert_response_to_html_create_html_message_build_and_encode_message_insert_reply_draft_remove_label)\n",
            "Generated TLDR: Automatically transfer email content with specific labels into OpenAI Assistant, generate a reply draft, and insert it into a Gmail thread, removing the trigger label afterwards.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'convert_response_to_html_create_html_message_build_and_encode_message_insert_reply_draft_remove_label'.\n",
            "\n",
            "Processing file: ðŸ”¥ðŸ“ˆðŸ¤– AI Agent for n8n Creators Leaderboard - Find Popular Workflows.txt\n",
            "Generated title: n8n_creator_leaderboard_stats_workflow (vector base ID: n8n_creator_leaderboard_stats_workflow)\n",
            "Generated TLDR: This automation workflow generates detailed statistics and insights on n8n workflow creators and their contributions, providing a comprehensive Markdown report based on fetched and processed data.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'n8n_creator_leaderboard_stats_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'n8n_creator_leaderboard_stats_workflow_1'.\n",
            "\n",
            "Processing file: Analyze feedback and send a message on Mattermost.txt\n",
            "Generated title: analyze_feedback_and_notify_mattermost (vector base ID: analyze_feedback_and_notify_mattermost)\n",
            "Generated TLDR: This automation workflow analyzes feedback sentiment and sends a message on Mattermost based on the sentiment score.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'analyze_feedback_and_notify_mattermost'.\n",
            "\n",
            "Processing file: Force AI to use a specific output format.txt\n",
            "Generated title: execute_workflow_llm_ai_output_parser_autofixing (vector base ID: execute_workflow_llm_ai_output_parser_autofixing)\n",
            "Generated TLDR: This automation workflow parses and validates structured output data based on a predefined format.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'execute_workflow_llm_ai_output_parser_autofixing'.\n",
            "\n",
            "Processing file: Prepare CSV files with GPT-4Prepare CSV files with GPT-4.txt\n",
            "Generated title: prepare_csv_files_with_gpt4 (vector base ID: prepare_csv_files_with_gpt4)\n",
            "Generated TLDR: This automation workflow generates 3 CSV files with funny user names and details provided by GPT-4.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'prepare_csv_files_with_gpt4'.\n",
            "Batch 10 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 11/59 ---\n",
            "\n",
            "Processing file: AI chat with any data source (using the n8n workflow tool).txt\n",
            "Generated title: ai_agent_hacker_news_slack_workflow (vector base ID: ai_agent_hacker_news_slack_workflow)\n",
            "Generated TLDR: This automation workflow fetches the top 50 posts on Hacker News, processes the data, and allows users to interact with an AI agent to inquire about the popularity of specific posts.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_hacker_news_slack_workflow'.\n",
            "\n",
            "Processing file: Organise Your Local File Directories With AI.txt\n",
            "Generated title: local_file_trigger_execute_command_lmchatmistralcloud_output_parser_execute_command (vector base ID: local_file_trigger_execute_command_lmchatmistralcloud_output_parser_execute_command)\n",
            "Generated TLDR: Monitors a target folder for changes, sorts and moves files into categorised subdirectories using Mistral AI suggestions.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'local_file_trigger_execute_command_lmchatmistralcloud_output_parser_execute_command'.\n",
            "\n",
            "Processing file: Send daily translated Calvin and Hobbes Comics to Discord.txt\n",
            "Generated title: daily_cartoon_translate_discord (vector base ID: daily_cartoon_translate_discord)\n",
            "Generated TLDR: This automation workflow retrieves daily Calvin and Hobbes comics, translates dialogues to English and Korean, and posts them to Discord.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'daily_cartoon_translate_discord'.\n",
            "\n",
            "Processing file: Twitter Virtual AI Influencer.txt\n",
            "Generated title: schedule_tweet_generation_and_posting (vector base ID: schedule_tweet_generation_and_posting)\n",
            "Generated TLDR: TLDR: This automation workflow generates potentially viral tweets every 6 hours, ensuring they meet length constraints and posts them to a Twitter account.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'schedule_tweet_generation_and_posting'.\n",
            "\n",
            "Processing file: Manipulate PDF with Adobe developer API.txt\n",
            "Generated title: workflow_test_pdf_extractionAdobe_API_calls (vector base ID: workflow_test_pdf_extractionAdobe_API_calls)\n",
            "Generated TLDR: This automation workflow authenticates, uploads a PDF asset to Adobe, waits for processing, and downloads the result.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'workflow_test_pdf_extractionAdobe_API_calls'.\n",
            "Batch 11 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 12/59 ---\n",
            "\n",
            "Processing file: AI-Powered Children_s English Storytelling on Telegram with OpenAI.txt\n",
            "Generated title: ai_childrens_story_generation_workflow (vector base ID: ai_childrens_story_generation_workflow)\n",
            "Generated TLDR: This automation workflow generates and shares AI-powered children's stories on Telegram every 12 hours.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_childrens_story_generation_workflow'.\n",
            "\n",
            "Processing file: Generate Text-to-Speech Using Elevenlabs via API.txt\n",
            "Generated title: generate_voice_using_elevenlabs_api (vector base ID: generate_voice_using_elevenlabs_api)\n",
            "Generated TLDR: This automation workflow generates text-to-speech using Elevenlabs via API with error handling.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_voice_using_elevenlabs_api'.\n",
            "\n",
            "Processing file: ðŸš€ Local Multi-LLM Testing & Performance Tracker.txt\n",
            "Generated title: testing_mulitple_local_llm_with_lm_studio (vector base ID: testing_mulitple_local_llm_with_lm_studio)\n",
            "Generated TLDR: This automation workflow analyzes responses from multiple language models and saves the results to a Google Sheet for tracking and comparison.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'testing_mulitple_local_llm_with_lm_studio'.\n",
            "\n",
            "Processing file: Translate Telegram audio messages with AI (55 supported languages).txt\n",
            "Generated title: telegram_audio_translator (vector base ID: telegram_audio_translator)\n",
            "Generated TLDR: This automation workflow translates audio messages in 55 languages on Telegram using AI.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_audio_translator'.\n",
            "\n",
            "Processing file: Telegram AI Chatbot.txt\n",
            "Generated title: telegram_ai_bot_workflow (vector base ID: telegram_ai_bot_workflow)\n",
            "Generated TLDR: This automation workflow serves as a Telegram AI-bot that responds to user messages, provides chatbot mode by default, creates images based on user requests using AI, and handles error messages for unsupported commands.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_ai_bot_workflow'.\n",
            "Batch 12 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 13/59 ---\n",
            "\n",
            "Processing file: Build a Financial Documents Assistant using Qdrant and Mistral.ai.txt\n",
            "Generated title: local_file_trigger_qdrant_chat_ai_agent (vector base ID: local_file_trigger_qdrant_chat_ai_agent)\n",
            "Generated TLDR: This automation workflow monitors a specific folder for changes, synchronizes files with Qdrant, and creates a Q&A AI agent on bank statements.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'local_file_trigger_qdrant_chat_ai_agent_0'.\n",
            "Upserted chunk 1 as vector ID 'local_file_trigger_qdrant_chat_ai_agent_1'.\n",
            "\n",
            "Processing file: Summarize Umami data with AI (via Openrouter) and save it to Baserow.txt\n",
            "Generated title: umami_to_ai_baserow (vector base ID: umami_to_ai_baserow)\n",
            "Generated TLDR: This automation workflow fetches view stats from Umami analytics, parses the data, sends it to A.I. for analysis, compares weekly data, and saves the results to Baserow.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'umami_to_ai_baserow'.\n",
            "\n",
            "Processing file: Extract spending history from gmail to google sheet.txt\n",
            "Generated title: extract_details_and_send_to_google_sheet (vector base ID: extract_details_and_send_to_google_sheet)\n",
            "Generated TLDR: This automation workflow extracts spend details from emails and sends them to a Google Sheet for record-keeping.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'extract_details_and_send_to_google_sheet_0'.\n",
            "Upserted chunk 1 as vector ID 'extract_details_and_send_to_google_sheet_1'.\n",
            "\n",
            "Processing file: Generating Image Embeddings via Textual Summarisation.txt\n",
            "Generated title: automated_image_embedding_workflow (vector base ID: automated_image_embedding_workflow)\n",
            "Generated TLDR: This automation workflow downloads an image from Google Drive, extracts color channel information, generates semantic keywords using OpenAI, and inserts the data into a vector store for search capabilities.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automated_image_embedding_workflow'.\n",
            "\n",
            "Processing file: Transcribe Audio Files, Summarize with GPT-4, and Store in Notion.txt\n",
            "Generated title: trigger_download_transcribe_notion (vector base ID: trigger_download_transcribe_notion)\n",
            "Generated TLDR: TLDR: This automation workflow triggers on a new audio file in Google Drive, downloads it, transcribes it with OpenAI, generates a summary, and sends the summary to a new Notion page.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'trigger_download_transcribe_notion'.\n",
            "Batch 13 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 14/59 ---\n",
            "\n",
            "Processing file: Build Your Own Image Search Using AI Object Detection, CDN and ElasticSearchBuild Your Own Image Search Using AI Object Detection, CDN and ElasticSearch.txt\n",
            "Generated title: image_processing_cloudflare_elasticsearch_slack_integration (vector base ID: image_processing_cloudflare_elasticsearch_slack_integration)\n",
            "Generated TLDR: This automation workflow downloads an image, uses an object classification AI model to identify objects in the image, crops the objects out into new images, and indexes the objects in an Elasticsearch Database for image search.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'image_processing_cloudflare_elasticsearch_slack_integration'.\n",
            "\n",
            "Processing file: MongoDB AI Agent - Intelligent Movie Recommendations.txt\n",
            "Generated title: ai_agent_movie_recommendation (vector base ID: ai_agent_movie_recommendation)\n",
            "Generated TLDR: This automation workflow creates an AI agent powered by OpenAI and MongoDB to handle chat messages, query data using MongoDB aggregation, and store favorite movies.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_movie_recommendation'.\n",
            "\n",
            "Processing file: Reconcile Rent Payments with Local Excel Spreadsheet and OpenAI.txt\n",
            "Generated title: watch_for_bank_statements_get_tenant_details_reconcile_rental_payments (vector base ID: watch_for_bank_statements_get_tenant_details_reconcile_rental_payments)\n",
            "Generated TLDR: This automation workflow ingests bank statements, analyzes them against a list of tenants using an AI agent, flags any issues such as missing payments or incorrect amounts, and exports them to an XLSX spreadsheet.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'watch_for_bank_statements_get_tenant_details_reconcile_rental_payments'.\n",
            "\n",
            "Processing file: Introduction to the HTTP Tool.txt\n",
            "Generated title: ai_agent_call_api_scrape_webpage_chat_interaction (vector base ID: ai_agent_call_api_scrape_webpage_chat_interaction)\n",
            "Generated TLDR: This automation workflow generates AI-generated chat responses and web scraping requests based on user input.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_call_api_scrape_webpage_chat_interaction'.\n",
            "\n",
            "Processing file: Speed Up Social Media Banners With BannerBear.com.txt\n",
            "Generated title: generate_ai_image_cloudinary_bannerbear_discord (vector base ID: generate_ai_image_cloudinary_bannerbear_discord)\n",
            "Generated TLDR: TLDR: This automation workflow generates event posters using AI and templates, uploads them to BannerBear via Cloudinary, and posts the final result on Discord.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_ai_image_cloudinary_bannerbear_discord'.\n",
            "Batch 14 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 15/59 ---\n",
            "\n",
            "Processing file: Get Airtable data via AI and Obsidian Notes.txt\n",
            "Generated title: get_airtable_data_ai_agent_obsidian_workflow (vector base ID: get_airtable_data_ai_agent_obsidian_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow integrates Airtable data with an AI Agent in Obsidian Notes for question processing and response generation.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'get_airtable_data_ai_agent_obsidian_workflow'.\n",
            "\n",
            "Processing file: Optimize & Update Printify Title and Description Workflow.txt\n",
            "Generated title: printify_update_title_and_description_algo (vector base ID: printify_update_title_and_description_algo)\n",
            "Generated TLDR: This automation updates title and description for products on Printify based on custom instructions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'printify_update_title_and_description_algo_0'.\n",
            "Upserted chunk 1 as vector ID 'printify_update_title_and_description_algo_1'.\n",
            "\n",
            "Processing file: Share YouTube Videos with AI Summaries on Discord.txt\n",
            "Generated title: youtube_videos_with_ai_summaries_on_discord (vector base ID: youtube_videos_with_ai_summaries_on_discord)\n",
            "Generated TLDR: This automation generates AI summaries for YouTube videos and posts them on Discord.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'youtube_videos_with_ai_summaries_on_discord'.\n",
            "\n",
            "Processing file: Use AI to organize your Todoist Inbox.txt\n",
            "Generated title: update_priority_in_todoist (vector base ID: update_priority_in_todoist)\n",
            "Generated TLDR: This automation workflow categorizes todo items and updates their priority in Todoist based on predefined projects.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'update_priority_in_todoist'.\n",
            "\n",
            "Processing file: Store Notion_s Pages as Vector Documents into Supabase with OpenAI.txt\n",
            "Generated title: store_notion_pages_vector_documents_supabase_openai (vector base ID: store_notion_pages_vector_documents_supabase_openai)\n",
            "Generated TLDR: This automation workflow stores Notion pages as vector documents in a Supabase database with OpenAI embeddings.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'store_notion_pages_vector_documents_supabase_openai'.\n",
            "Batch 15 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 16/59 ---\n",
            "\n",
            "Processing file: ChatGPT Automatic Code Review in Gitlab MR.txt\n",
            "Generated title: sticky_note_webhook_code_split_out_get_changes_need_review_basic_llm_chain_post_discussions_skip_file_change_openai_chat_model_parse_last_diff_line_need_review_discussions (vector base ID: sticky_note_webhook_code_split_out_get_changes_need_review_basic_llm_chain_post_discussions_skip_file_change_openai_chat_model_parse_last_diff_line_need_review_discussions)\n",
            "Generated TLDR: This automation workflow automates code review and discussion on GitLab merge requests.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'sticky_note_webhook_code_split_out_get_changes_need_review_basic_llm_chain_post_discussions_skip_file_change_openai_chat_model_parse_last_diff_line_need_review_discussions'.\n",
            "\n",
            "Processing file: Query n8n Credentials with AI SQL Agent.txt\n",
            "Generated title: map_workflows_credentials_and_query_agent (vector base ID: map_workflows_credentials_and_query_agent)\n",
            "Generated TLDR: This automation workflow helps users query workflow credentials using an AI SQL agent.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'map_workflows_credentials_and_query_agent'.\n",
            "\n",
            "Processing file: Create, update, and get a profile in Humantic AI.txt\n",
            "Generated title: create_update_get_profile_humantic_ai (vector base ID: create_update_get_profile_humantic_ai)\n",
            "Generated TLDR: TLDR: This automation workflow creates, updates, and retrieves a profile in Humantic AI based on user input.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'create_update_get_profile_humantic_ai'.\n",
            "\n",
            "Processing file: Automate Your RFP Process with OpenAI Assistants.txt\n",
            "Generated title: workflow_rfp_response_generation_with_llm_ai_integration (vector base ID: workflow_rfp_response_generation_with_llm_ai_integration)\n",
            "Generated TLDR: This automation workflow processes RFP documents by extracting questions, generating answers using AI, and creating a response document.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'workflow_rfp_response_generation_with_llm_ai_integration'.\n",
            "\n",
            "Processing file: Recipe Recommendations with Qdrant and Mistral.txt\n",
            "Generated title: recipe_recommendations_qdrant_mistral (vector base ID: recipe_recommendations_qdrant_mistral)\n",
            "Generated TLDR: Fetches and stores HelloFresh's weekly menu, builds a recommendation engine for meal suggestions, and enables AI-powered chat recommendations based on user preferences using Qdrant and Mistral technology.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'recipe_recommendations_qdrant_mistral_0'.\n",
            "Upserted chunk 1 as vector ID 'recipe_recommendations_qdrant_mistral_1'.\n",
            "Batch 16 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 17/59 ---\n",
            "\n",
            "Processing file: Author and Publish Blog Posts From Google Sheets.txt\n",
            "Generated title: agent_blog_post_publishing_workflow (vector base ID: agent_blog_post_publishing_workflow)\n",
            "Generated TLDR: This automation workflow handles the process of authoring blog posts, including data configuration, post-processing, and publishing to WordPress, while logging information and status updates in a Google Sheets document.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_blog_post_publishing_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'agent_blog_post_publishing_workflow_1'.\n",
            "\n",
            "Processing file: Enrich Property Inventory Survey with Image Recognition and AI Agent.txt\n",
            "Generated title: ai_agent_airtable_enrichment_workflow (vector base ID: ai_agent_airtable_enrichment_workflow)\n",
            "Generated TLDR: This automation workflow uses AI models and tools to enrich product data in an Airtable spreadsheet using image analysis and web scraping.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_airtable_enrichment_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_airtable_enrichment_workflow_1'.\n",
            "\n",
            "Processing file: Extract Information from a Logo Sheet using forms, AI, Google Sheet and Airtable.txt\n",
            "Generated title: ai_logo_sheet_extractor_to_airtable (vector base ID: ai_logo_sheet_extractor_to_airtable)\n",
            "Generated TLDR: This automation extracts attributes and creates tools with similarities from uploaded logo sheets to Airtable.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_logo_sheet_extractor_to_airtable_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_logo_sheet_extractor_to_airtable_1'.\n",
            "\n",
            "Processing file: Telegram to Spotify with OpenAI.txt\n",
            "Generated title: telegram_to_spotify_ask_ai_about_track (vector base ID: telegram_to_spotify_ask_ai_about_track)\n",
            "Generated TLDR: TLDR: This automation workflow allows users to ask an AI about a track with artist and song name, search for the track on Spotify, and control Spotify playlists via Telegram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_to_spotify_ask_ai_about_track'.\n",
            "\n",
            "Processing file: Enhance Customer Chat by Buffering Messages with Twilio and Redis.txt\n",
            "Generated title: ai_agent_reply_processing_workflow (vector base ID: ai_agent_reply_processing_workflow)\n",
            "Generated TLDR: This automation workflow processes incoming messages from Twilio and uses an AI Agent to generate a single response for multiple messages.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_reply_processing_workflow'.\n",
            "Batch 17 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 18/59 ---\n",
            "\n",
            "Processing file: AI-powered WooCommerce Support-Agent.txt\n",
            "Generated title: ai_agent_wooCommerce_order_tool_tracking_workflow (vector base ID: ai_agent_wooCommerce_order_tool_tracking_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow retrieves WooCommerce user and order information, decrypts email addresses, and checks and processes DHL tracking data for orders.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_wooCommerce_order_tool_tracking_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_wooCommerce_order_tool_tracking_workflow_1'.\n",
            "\n",
            "Processing file: Survey Insights with Qdrant, Python and Information Extractor.txt\n",
            "Generated title: survey_insights_agent_workflow (vector base ID: survey_insights_agent_workflow)\n",
            "Generated TLDR: This automation workflow processes survey responses to extract insights by clustering similar answers to each question.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'survey_insights_agent_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'survey_insights_agent_workflow_1'.\n",
            "\n",
            "Processing file: Send a ChatGPT email reply and save responses to Google Sheets.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26388 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26388 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26388 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26388 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26388 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: Send a ChatGPT email reply and save responses to Google Sheets.txt (vector base ID: Send a ChatGPT email reply and save responses to Google Sheets.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26352 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26352 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26352 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26352 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 26352 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 5 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'Send a ChatGPT email reply and save responses to Google Sheets.txt_0'.\n",
            "Upserted chunk 1 as vector ID 'Send a ChatGPT email reply and save responses to Google Sheets.txt_1'.\n",
            "Upserted chunk 2 as vector ID 'Send a ChatGPT email reply and save responses to Google Sheets.txt_2'.\n",
            "Upserted chunk 3 as vector ID 'Send a ChatGPT email reply and save responses to Google Sheets.txt_3'.\n",
            "Upserted chunk 4 as vector ID 'Send a ChatGPT email reply and save responses to Google Sheets.txt_4'.\n",
            "\n",
            "Processing file: KB Tool - Confluence Knowledge Base.txt\n",
            "Generated title: enhance_query_resolution_with_knowledge_base_tool (vector base ID: enhance_query_resolution_with_knowledge_base_tool)\n",
            "Generated TLDR: This automation workflow enhances IT support by integrating a Knowledge Base Tool for dynamic search and response capabilities, utilizing AI query transformation and Confluence integration.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'enhance_query_resolution_with_knowledge_base_tool'.\n",
            "\n",
            "Processing file: Visual Regression Testing with Apify and AI Vision Model.txt\n",
            "Generated title: visual_regression_agent (vector base ID: visual_regression_agent)\n",
            "Generated TLDR: This automation workflow performs visual regression testing on webpages using AI vision models.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'visual_regression_agent_0'.\n",
            "Upserted chunk 1 as vector ID 'visual_regression_agent_1'.\n",
            "Batch 18 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 19/59 ---\n",
            "\n",
            "Processing file: Automated AI image analysis and response via Telegram.txt\n",
            "Generated title: automated_image_analysis_telegram_workflow (vector base ID: automated_image_analysis_telegram_workflow)\n",
            "Generated TLDR: Automated Image Analysis and Response via Telegram: Streamlines image analysis process by analyzing images sent via Telegram and providing insightful responses based on the analysis outcomes.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automated_image_analysis_telegram_workflow'.\n",
            "\n",
            "Processing file: Customer Support Channel and Ticketing System with Slack and Linear.txt\n",
            "Generated title: slack_linear_chatgpt_linear. (vector base ID: slack_linear_chatgpt_linear.)\n",
            "Generated TLDR: This automation workflow monitors a Slack channel for messages with a ticket emoji, uses AI to generate ticket content, and creates support tickets in Linear.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'slack_linear_chatgpt_linear.'.\n",
            "\n",
            "Processing file: Summarize your emails with A.I. (via Openrouter) and send to Line messenger (1).txt\n",
            "Generated title: summarize_emails_with_ai_then_send_to_messenger (vector base ID: summarize_emails_with_ai_then_send_to_messenger)\n",
            "Generated TLDR: Summarize emails using A.I. and send the summary to messenger.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'summarize_emails_with_ai_then_send_to_messenger'.\n",
            "\n",
            "Processing file: Automated Hugging Face Paper Summary Fetching & Categorization Workflow.txt\n",
            "Generated title: crop_anomaly_detection_tool (vector base ID: crop_anomaly_detection_tool)\n",
            "Generated TLDR: This automation workflow detects anomalies in crop images by comparing them to a dataset using embedding and threshold scoring.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'crop_anomaly_detection_tool'.\n",
            "\n",
            "Processing file: IT Ops AI SlackBot Workflow - Chat with your knowledge base.txt\n",
            "Generated title: it_ops_ai_slackbot_workflow (vector base ID: it_ops_ai_slackbot_workflow)\n",
            "Generated TLDR: This automation workflow integrates Slack messaging with AI-powered responses to streamline IT inquiries and enhance support services.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'it_ops_ai_slackbot_workflow'.\n",
            "Batch 19 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 20/59 ---\n",
            "\n",
            "Processing file: Text automations using Apple Shortcuts (1).txt\n",
            "Generated title: text_automations_using_apple_shortcuts (vector base ID: text_automations_using_apple_shortcuts)\n",
            "Generated TLDR: This automation workflow uses Apple Shortcuts to send text requests that are processed by OpenAI nodes for translation, grammar correction, and text length adjustments.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'text_automations_using_apple_shortcuts'.\n",
            "\n",
            "Processing file: Breakdown Documents into Study Notes using Templating MistralAI and Qdrant.txt\n",
            "Generated title: generate_notes_from_source_document (vector base ID: generate_notes_from_source_document)\n",
            "Generated TLDR: This automation workflow generates notes from a source document using multiple AI agents with templates, and exports the generated notes alongside the original document.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_notes_from_source_document_0'.\n",
            "Upserted chunk 1 as vector ID 'generate_notes_from_source_document_1'.\n",
            "\n",
            "Processing file: Suggest meeting slots using AI.txt\n",
            "Generated title: calendar_scheduling_workflow (vector base ID: calendar_scheduling_workflow)\n",
            "Generated TLDR: This automation workflow checks incoming emails for appointment requests, evaluates them using AI, extracts calendar availability, and sends appropriate responses.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'calendar_scheduling_workflow'.\n",
            "\n",
            "Processing file: Text automations using Apple Shortcuts.txt\n",
            "Generated title: text_automations_using_apple_shortcuts_workflow. (vector base ID: text_automations_using_apple_shortcuts_workflow.)\n",
            "Generated TLDR: This automation workflow processes text requests from Apple Shortcuts by using OpenAI for translation, grammar correction, and content length adjustments.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'text_automations_using_apple_shortcuts_workflow.'.\n",
            "\n",
            "Processing file: Sentiment Analysis Tracking on Support Issues with Linear and Slack.txt\n",
            "Generated title: issues_to_list_ai_sentiment_analysis_airtable_slack_notification (vector base ID: issues_to_list_ai_sentiment_analysis_airtable_slack_notification)\n",
            "Generated TLDR: This automation workflow continuously monitors active Linear issues, performs sentiment analysis on issue activity, tracks results in Airtable, and notifies when sentiment becomes negative.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'issues_to_list_ai_sentiment_analysis_airtable_slack_notification'.\n",
            "Batch 20 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 21/59 ---\n",
            "\n",
            "Processing file: Auto-label incoming Gmail messages with AI nodes.txt\n",
            "Generated title: gmail_message_label_automation (vector base ID: gmail_message_label_automation)\n",
            "Generated TLDR: This automation workflow categorizes Gmail messages by assigning labels based on their content.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_message_label_automation'.\n",
            "\n",
            "Processing file: Convert URL HTML to Markdown Format and Get Page Links.txt\n",
            "Generated title: clicking_test_workflow_urls_to_markdown (vector base ID: clicking_test_workflow_urls_to_markdown)\n",
            "Generated TLDR: This automation workflow converts web page HTML content to markdown format and extracts links, handling API rate limits, and processing URLs in batches from a database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'clicking_test_workflow_urls_to_markdown'.\n",
            "\n",
            "Processing file: Creating a AI Slack Bot with Google Gemini.txt\n",
            "Generated title: webhook_to_slack_with_ai_agent (vector base ID: webhook_to_slack_with_ai_agent)\n",
            "Generated TLDR: This automation receives a POST webhook, processes data using an AI agent, and sends the response back to a Slack channel.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'webhook_to_slack_with_ai_agent'.\n",
            "\n",
            "Processing file: Dynamically generate a webpage from user request using OpenAI Structured Output (1).txt\n",
            "Generated title: dynamically_generate_html_page_from_user_request_using_openai_structured_output (vector base ID: dynamically_generate_html_page_from_user_request_using_openai_structured_output)\n",
            "Generated TLDR: TLDR: This automation workflow dynamically generates an HTML page from a user request using OpenAI Structured Output.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'dynamically_generate_html_page_from_user_request_using_openai_structured_output'.\n",
            "\n",
            "Processing file: Chat with a Google Sheet using AI.txt\n",
            "Generated title: chat_with_google_sheet_ai_agent (vector base ID: chat_with_google_sheet_ai_agent)\n",
            "Generated TLDR: This automation workflow enables an AI agent to interact with a Google Sheet using custom tools to retrieve specific data based on user queries.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'chat_with_google_sheet_ai_agent'.\n",
            "Batch 21 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 22/59 ---\n",
            "\n",
            "Processing file: Dynamically generate a webpage from user request using OpenAI Structured Output.txt\n",
            "Generated title: generate_html_page_from_user_request_using_openai_structured_output (vector base ID: generate_html_page_from_user_request_using_openai_structured_output)\n",
            "Generated TLDR: Generates an HTML page dynamically from a user request using OpenAI structured output.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_html_page_from_user_request_using_openai_structured_output'.\n",
            "\n",
            "Processing file: Image Creation with OpenAI and Telegram.txt\n",
            "Generated title: telegram_trigger_openai_merge_telegram (vector base ID: telegram_trigger_openai_merge_telegram)\n",
            "Generated TLDR: This automation workflow uses AI to enhance image processing and communication on Telegram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_trigger_openai_merge_telegram'.\n",
            "\n",
            "Processing file: AI chatbot that can search the web.txt\n",
            "Generated title: ai_agent_chat_responses_workflow (vector base ID: ai_agent_chat_responses_workflow)\n",
            "Generated TLDR: AI Agent utilizing various tools and memory to answer prompts and chat messages.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chat_responses_workflow'.\n",
            "\n",
            "Processing file: Sentiment Analysis Tracking on Support Issues with Linear and Slack (1).txt\n",
            "Generated title: issues_sentiment_analysis_airtable_slack (vector base ID: issues_sentiment_analysis_airtable_slack)\n",
            "Generated TLDR: This automation workflow continuously monitors active Linear issue conversations, performs sentiment analysis, and alerts when the sentiment becomes negative.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'issues_sentiment_analysis_airtable_slack'.\n",
            "\n",
            "Processing file: Send Google analytics data to A.I. to analyze then save results in BaserowSend Google analytics data to A.I. to analyze then save results in Baserow.txt\n",
            "Generated title: send_page_data_to_ai_base_row (vector base ID: send_page_data_to_ai_base_row)\n",
            "Generated TLDR: This automation workflow sends Google analytics data to A.I., compares data from the past two weeks, and provides suggestions to improve SEO.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'send_page_data_to_ai_base_row_0'.\n",
            "Upserted chunk 1 as vector ID 'send_page_data_to_ai_base_row_1'.\n",
            "Batch 22 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 23/59 ---\n",
            "\n",
            "Processing file: Telegram Bot with Supabase memory and OpenAI assistant integration.txt\n",
            "Generated title: telegram_openai_supabase_integration (vector base ID: telegram_openai_supabase_integration)\n",
            "Generated TLDR: This automation workflow creates an AI Telegram Bot with Supabase memory to maintain context and user interactions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_openai_supabase_integration_0'.\n",
            "Upserted chunk 1 as vector ID 'telegram_openai_supabase_integration_1'.\n",
            "\n",
            "Processing file: Automate LinkedIn Outreach with Notion and OpenAI.txt\n",
            "Generated title: automate_linkedin_posts_with_ai (vector base ID: automate_linkedin_posts_with_ai)\n",
            "Generated TLDR: Automate posting daily content on LinkedIn with AI-generated text and images from a Notion database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automate_linkedin_posts_with_ai'.\n",
            "\n",
            "Processing file: Vector Database as a Big Data Analysis Tool for AI Agents [2_2 KNN] (1).txt\n",
            "Generated title: knn_classification_tool (vector base ID: knn_classification_tool)\n",
            "Generated TLDR: This automation workflow is a KNN classifier tool that classifies input images based on queries to the Qdrant collection of land types.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'knn_classification_tool'.\n",
            "\n",
            "Processing file: AI Crew to Automate Fundamental Stock Analysis - Q&A Workflow.txt\n",
            "Generated title: stock_qa_workflow (vector base ID: stock_qa_workflow)\n",
            "Generated TLDR: This workflow extracts and responds to questions from a user's manual chat message using AI-powered language models and vector stores.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'stock_qa_workflow'.\n",
            "\n",
            "Processing file: Handling Appointment Leads and Follow-up With Twilio, Cal.com and AI.txt\n",
            "Generated title: twilio_airtable_follow_up_workflow (vector base ID: twilio_airtable_follow_up_workflow)\n",
            "Generated TLDR: This automation workflow schedules appointments via SMS, handles follow-up messages, and manages appointment details.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'twilio_airtable_follow_up_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'twilio_airtable_follow_up_workflow_1'.\n",
            "Upserted chunk 2 as vector ID 'twilio_airtable_follow_up_workflow_2'.\n",
            "Batch 23 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 24/59 ---\n",
            "\n",
            "Processing file: Customer Insights with Qdrant, Python and Information Extractor.txt\n",
            "Generated title: customer_insights_agent_workflow (vector base ID: customer_insights_agent_workflow)\n",
            "Generated TLDR: Scrape TrustPilot reviews, group them using K-means clustering, and generate insights using LLM for a specified company.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'customer_insights_agent_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'customer_insights_agent_workflow_1'.\n",
            "\n",
            "Processing file: Gmail AI Auto-Responder_ Create Draft Replies to incoming emails.txt\n",
            "Generated title: gmail_autoresponder_draft_reply_draft_generation (vector base ID: gmail_autoresponder_draft_reply_draft_generation)\n",
            "Generated TLDR: TLDR: This automation workflow uses AI to assess incoming emails, generate appropriate draft replies, and create them in Gmail.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_autoresponder_draft_reply_draft_generation'.\n",
            "\n",
            "Processing file: Turn Emails into AI-Enhanced Tasks in Notion (Multi-User Support) with Gmail, Airtable and Softr.txt\n",
            "Generated title: agent_gmail_notion_integration (vector base ID: agent_gmail_notion_integration)\n",
            "Generated TLDR: This automation workflow processes incoming emails, extracts relevant information, creates actionable tasks, and notifies users about deactivated routes or errors.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_gmail_notion_integration_0'.\n",
            "Upserted chunk 1 as vector ID 'agent_gmail_notion_integration_1'.\n",
            "\n",
            "Processing file: Chat with PDF docs using AI (quoting sources).txt\n",
            "Generated title: agent_google_drive_pinecone_chat_integration (vector base ID: agent_google_drive_pinecone_chat_integration)\n",
            "Generated TLDR: Fetch file from Google Drive, split it into chunks, insert into a vector database, and use AI models to chat and generate responses based on the file content.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_google_drive_pinecone_chat_integration'.\n",
            "\n",
            "Processing file: create e-mail responses with fastmail and OpenAI.txt\n",
            "Generated title: fastmail_draft_generation_workflow (vector base ID: fastmail_draft_generation_workflow)\n",
            "Generated TLDR: This automation workflow drafts email responses using OpenAI's GPT-4 model for Fastmail accounts.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'fastmail_draft_generation_workflow'.\n",
            "Batch 24 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 25/59 ---\n",
            "\n",
            "Processing file: Talk to your SQLite database with a LangChain AI Agent.txt\n",
            "Generated title: sql_agent_with_memory_codegen_workflow (vector base ID: sql_agent_with_memory_codegen_workflow)\n",
            "Generated TLDR: This automation workflow uses an AI agent to interact with a local SQLite database based on chat inputs.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'sql_agent_with_memory_codegen_workflow'.\n",
            "\n",
            "Processing file: Prompt-based Object Detection with Gemini 2.0.txt\n",
            "Generated title: gemini_2_0_object_detection_workflow (vector base ID: gemini_2_0_object_detection_workflow)\n",
            "Generated TLDR: This automation workflow downloads an image, uses a machine learning API to detect objects in the image, scales the coordinates of the detected objects, and then draws bounding boxes around them on the original image.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gemini_2_0_object_detection_workflow'.\n",
            "\n",
            "Processing file: Enrich FAQ sections on your website pages at scale with AI.txt\n",
            "Generated title: define_sheets_google_drive_integration_workflow (vector base ID: define_sheets_google_drive_integration_workflow)\n",
            "Generated TLDR: This automation workflow generates Q&A templates for different service integrations and uploads them to Google Drive after AI completion.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'define_sheets_google_drive_integration_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'define_sheets_google_drive_integration_workflow_1'.\n",
            "\n",
            "Processing file: Build a Tax Code Assistant with Qdrant, Mistral.ai and OpenAI.txt\n",
            "Generated title: tax_code_assistant_chatbot (vector base ID: tax_code_assistant_chatbot)\n",
            "Generated TLDR: This automation workflow extracts tax code sections from a PDF, partitions them, saves them into a database, and powers a chatbot for answering tax-related questions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'tax_code_assistant_chatbot_0'.\n",
            "Upserted chunk 1 as vector ID 'tax_code_assistant_chatbot_1'.\n",
            "\n",
            "Processing file: Invoice data extraction with LlamaParse and OpenAI.txt\n",
            "Generated title: llamaparse_gmail_pdf_extraction_google_sheet (vector base ID: llamaparse_gmail_pdf_extraction_google_sheet)\n",
            "Generated TLDR: This automation workflow extracts data from PDF invoice emails and uploads it to a Google Sheet for reconciliation.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'llamaparse_gmail_pdf_extraction_google_sheet_0'.\n",
            "Upserted chunk 1 as vector ID 'llamaparse_gmail_pdf_extraction_google_sheet_1'.\n",
            "Batch 25 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 26/59 ---\n",
            "\n",
            "Processing file: Email Subscription Service with n8n Forms, Airtable and AI (1).txt\n",
            "Generated title: scheduled_email_service_workflow (vector base ID: scheduled_email_service_workflow)\n",
            "Generated TLDR: This automation workflow sends scheduled emails with facts based on user subscriptions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'scheduled_email_service_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'scheduled_email_service_workflow_1'.\n",
            "\n",
            "Processing file: OpenAI Assistant workflow_ upload file, create an Assistant, chat with it!.txt\n",
            "Generated title: upload_google_drive_to_openai (vector base ID: upload_google_drive_to_openai)\n",
            "Generated TLDR: This automation workflow uploads a Google Drive file to OpenAI, creates a new Assistant for a music festival, and enables chatting with the Assistant using retrieved knowledge from the uploaded document.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'upload_google_drive_to_openai'.\n",
            "\n",
            "Processing file: Telegram AI bot with LangChain nodes.txt\n",
            "Generated title: telegram_ai_langchain_bot_send_image_via_telegram (vector base ID: telegram_ai_langchain_bot_send_image_via_telegram)\n",
            "Generated TLDR: This automation workflow generates an image with Dall-E 3 and sends it via Telegram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_ai_langchain_bot_send_image_via_telegram'.\n",
            "\n",
            "Processing file: Vector Database as a Big Data Analysis Tool for AI Agents [2_3 - anomaly].txt\n",
            "Generated title: set_up_medoids_for_anomaly_detection (vector base ID: set_up_medoids_for_anomaly_detection)\n",
            "Generated TLDR: Set up medoids for anomaly detection using two different approaches: distance matrix and multimodal embedding model.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'set_up_medoids_for_anomaly_detection_0'.\n",
            "Upserted chunk 1 as vector ID 'set_up_medoids_for_anomaly_detection_1'.\n",
            "\n",
            "Processing file: Generate audio from text using OpenAI and Webhook _ Text to Speech Workflow.txt\n",
            "Generated title: webhook_openai_audio_generation (vector base ID: webhook_openai_audio_generation)\n",
            "Generated TLDR: Generate audio from text using OpenAI's text-to-speech functionality in response to a webhook trigger.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'webhook_openai_audio_generation'.\n",
            "Batch 26 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 27/59 ---\n",
            "\n",
            "Processing file: Chat with OpenAIs GPT via a simple Telegram Bot.txt\n",
            "Generated title: ai_agent_telegram_chatåŠŸèƒ½ (vector base ID: ai_agent_telegram_chat)\n",
            "Generated TLDR: This automation workflow uses a Telegram trigger to chat with an OpenAI chat model and respond to messages using emojis.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_telegram_chat'.\n",
            "\n",
            "Processing file: Telegram AI Bot_ NeurochainAI Text & Image - NeurochainAI Basic API Integration.txt\n",
            "Generated title: neurochainai_basic_api_integration_workflow (vector base ID: neurochainai_basic_api_integration_workflow)\n",
            "Generated TLDR: This automation workflow sends a prompt to a NeurochainAI REST API, generates an image based on the response, and sends it to a Telegram chat.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'neurochainai_basic_api_integration_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'neurochainai_basic_api_integration_workflow_1'.\n",
            "\n",
            "Processing file: Ask questions about a PDF using AI.txt\n",
            "Generated title: google_drive_vector_store_chat_workflow (vector base ID: google_drive_vector_store_chat_workflow)\n",
            "Generated TLDR: This automation workflow fetches a file from Google Drive, splits it into chunks, and inserts them into a Pinecone index for retrieval and chat-based querying.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_drive_vector_store_chat_workflow'.\n",
            "\n",
            "Processing file: Summarize your emails with A.I. (via Openrouter) and send to Line messenger.txt\n",
            "Generated title: summarize_emails_ai_send_messenger (vector base ID: summarize_emails_ai_send_messenger)\n",
            "Generated TLDR: Summarize emails using AI and send to messenger.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'summarize_emails_ai_send_messenger'.\n",
            "\n",
            "Processing file: Easy Image Captioning with Gemini 1.5 Pro.txt\n",
            "Generated title: image_captioning_agent_google_gemini_caption_overlay (vector base ID: image_captioning_agent_google_gemini_caption_overlay)\n",
            "Generated TLDR: This automation workflow generates image captions using AI models and overlays them onto images.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'image_captioning_agent_google_gemini_caption_overlay'.\n",
            "Batch 27 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 28/59 ---\n",
            "\n",
            "Processing file: Supabase Insertion & Upsertion & Retrieval.txt\n",
            "Generated title: embeddings_openai_insertion_vector_database_integration (vector base ID: embeddings_openai_insertion_vector_database_integration)\n",
            "Generated TLDR: This automation workflow retrieves, inserts, updates, and customizes responses using text embeddings and vectors stored in a Supabase database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'embeddings_openai_insertion_vector_database_integration'.\n",
            "\n",
            "Processing file: Autonomous AI crawler.txt\n",
            "Generated title: crawl_website_and_extract_social_media_urls. (vector base ID: crawl_website_and_extract_social_media_urls.)\n",
            "Generated TLDR: This automation workflow extracts social media profile URLs from websites and inserts them into a database.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'crawl_website_and_extract_social_media_urls._0'.\n",
            "Upserted chunk 1 as vector ID 'crawl_website_and_extract_social_media_urls._1'.\n",
            "\n",
            "Processing file: Automate Competitor Research with Exa.ai, Notion and AI Agents.txt\n",
            "Generated title: automate_competitor_research_with_exa_ai_notion_ai_agents (vector base ID: automate_competitor_research_with_exa_ai_notion_ai_agents)\n",
            "Generated TLDR: Automate competitor research using Exa.ai, Notion, and AI agents.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automate_competitor_research_with_exa_ai_notion_ai_agents_0'.\n",
            "Upserted chunk 1 as vector ID 'automate_competitor_research_with_exa_ai_notion_ai_agents_1'.\n",
            "\n",
            "Processing file: Write a WordPress post with AI (starting from a few keywords).txt\n",
            "Generated title: write_a_wordpress_post_with_ai_from_few_keywords (vector base ID: write_a_wordpress_post_with_ai_from_few_keywords)\n",
            "Generated TLDR: This workflow automates the generation and posting of a WordPress article based on AI-generated content provided by the user.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'write_a_wordpress_post_with_ai_from_few_keywords_0'.\n",
            "Upserted chunk 1 as vector ID 'write_a_wordpress_post_with_ai_from_few_keywords_1'.\n",
            "\n",
            "Processing file: Parse PDF with LlamaParse and save to Airtable.txt\n",
            "Generated title: google_drive_trigger_webhook_parse_pdf_airtable (vector base ID: google_drive_trigger_webhook_parse_pdf_airtable)\n",
            "Generated TLDR: Parse PDF with LlamaParse and save to Airtable.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_drive_trigger_webhook_parse_pdf_airtable'.\n",
            "Batch 28 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 29/59 ---\n",
            "\n",
            "Processing file: ðŸ“ˆ Receive Daily Market News from FT.com to your Microsoft outlook inbox.txt\n",
            "Generated title: financial_news_recap_workflow (vector base ID: financial_news_recap_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow extracts financial news content from a website, structures the data, summarizes it with an AI model, and sends a daily email with a clear market overview.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'financial_news_recap_workflow'.\n",
            "\n",
            "Processing file: Notion knowledge base AI assistant.txt\n",
            "Generated title: notion_knowledge_base_assistant (vector base ID: notion_knowledge_base_assistant)\n",
            "Generated TLDR: This automation workflow assists users by retrieving information from a Notion knowledge base using AI technology.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'notion_knowledge_base_assistant'.\n",
            "\n",
            "Processing file: Flux Dev Image Generation (Fal.ai) to Google Drive.txt\n",
            "Generated title: fal_flux_image_generation_workflow (vector base ID: fal_flux_image_generation_workflow)\n",
            "Generated TLDR: This automation workflow generates images based on provided prompts and settings and saves them to Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'fal_flux_image_generation_workflow'.\n",
            "\n",
            "Processing file: Deduplicate Scraping AI Grants for Eligibility using AI.txt\n",
            "Generated title: grant_tracker_notification_emails (vector base ID: grant_tracker_notification_emails)\n",
            "Generated TLDR: This automation workflow fetches and summarizes new AI grants from grants.gov, determines eligibility using AI, saves grant details to a tracker, generates and sends a daily newsletter email to subscribers.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'grant_tracker_notification_emails_0'.\n",
            "Upserted chunk 1 as vector ID 'grant_tracker_notification_emails_1'.\n",
            "\n",
            "Processing file: Handling Job Application Submissions with AI and n8n Forms.txt\n",
            "Generated title: application_submission_with_ai_integration (vector base ID: application_submission_with_ai_integration)\n",
            "Generated TLDR: This automation workflow processes job applications by extracting information from CVs, classifying documents, prefills job application forms, and saves applicant data to an Applicant Tracking System.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'application_submission_with_ai_integration_0'.\n",
            "Upserted chunk 1 as vector ID 'application_submission_with_ai_integration_1'.\n",
            "Batch 29 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 30/59 ---\n",
            "\n",
            "Processing file: Telegram chat with PDF.txt\n",
            "Generated title: telegram_rag_pdf_workflow (vector base ID: telegram_rag_pdf_workflow)\n",
            "Generated TLDR: This automation workflow processes PDF files received from Telegram, extracts text, stores it in a database for retrieval, and generates responses based on user queries.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_rag_pdf_workflow'.\n",
            "\n",
            "Processing file: Extract insights & analyse YouTube comments via AI Agent chat.txt\n",
            "Generated title: ai_agent_youtube_insights_extraction (vector base ID: ai_agent_youtube_insights_extraction)\n",
            "Generated TLDR: This automation workflow extracts insights from YouTube videos and comments to power content creation.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_youtube_insights_extraction_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_youtube_insights_extraction_1'.\n",
            "\n",
            "Processing file: Transcribing Bank Statements To Markdown Using Gemini Vision AI.txt\n",
            "Generated title: transcribe_bank_statement_to_markdown_using_gemini_model (vector base ID: transcribe_bank_statement_to_markdown_using_gemini_model)\n",
            "Generated TLDR: This automation workflow converts a bank statement to markdown using Vision Language Models (VLMs) for data extraction.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'transcribe_bank_statement_to_markdown_using_gemini_model'.\n",
            "\n",
            "Processing file: Analyze & Sort Suspicious Email Contents with ChatGPT.txt\n",
            "Generated title: gmail_outlook_email_analysis_workflow (vector base ID: gmail_outlook_email_analysis_workflow)\n",
            "Generated TLDR: This automation workflow detects and analyzes incoming emails, using AI to determine if they are potentially malicious or benign, then creates corresponding Jira tickets with detailed analysis and attachments.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_outlook_email_analysis_workflow'.\n",
            "\n",
            "Processing file: Chat with OpenAI Assistant (by adding a memory).txt\n",
            "Generated title: openai_assistant_integration_workflow (vector base ID: openai_assistant_integration_workflow)\n",
            "Generated TLDR: This automation workflow integrates an OpenAI Assistant to chat with users, storing and recalling previous conversations.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'openai_assistant_integration_workflow'.\n",
            "Batch 30 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 31/59 ---\n",
            "\n",
            "Processing file: Actioning Your Meeting Next Steps using Transcripts and AI.txt\n",
            "Generated title: google_meets_transcript_ai_agent_schedule_meeting_workflow (vector base ID: google_meets_transcript_ai_agent_schedule_meeting_workflow)\n",
            "Generated TLDR: This automation workflow retrieves a meeting transcript, analyzes it with AI, creates a calendar event, and invites attendees based on the transcript content.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_meets_transcript_ai_agent_schedule_meeting_workflow'.\n",
            "\n",
            "Processing file: Invoice data extraction with LlamaParse and OpenAI (1).txt\n",
            "Generated title: llamaparse_gmail_lnm_extract_invoice (vector base ID: llamaparse_gmail_lnm_extract_invoice)\n",
            "Generated TLDR: This automation workflow extracts data from email invoices, processes it using LlamaParse and a language model, then exports it to a Google Sheet while ensuring email duplicates are avoided.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'llamaparse_gmail_lnm_extract_invoice_0'.\n",
            "Upserted chunk 1 as vector ID 'llamaparse_gmail_lnm_extract_invoice_1'.\n",
            "\n",
            "Processing file: Analyze Suspicious Email Contents with ChatGPT Vision.txt\n",
            "Generated title: gmail_outlook_email_analysis_ticketing_workflow (vector base ID: gmail_outlook_email_analysis_ticketing_workflow)\n",
            "Generated TLDR: This automation workflow processes incoming emails from Gmail and Microsoft Outlook, extracts key components, generates visual representations, performs AI analysis for phishing indicators, and automates the creation of detailed Jira tickets for phishing reports.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_outlook_email_analysis_ticketing_workflow'.\n",
            "\n",
            "Processing file: Screen Applicants With AI, notify HR and save them in a Google Sheet.txt\n",
            "Generated title: ai_cv_screening_workflow (vector base ID: ai_cv_screening_workflow)\n",
            "Generated TLDR: Automated AI CV screening workflow that analyzes candidate resumes and notifies HR about new CV submissions.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_cv_screening_workflow'.\n",
            "\n",
            "Processing file: Automate Image Validation Tasks using AI Vision.txt\n",
            "Generated title: passport_photo_validation_ai_workflow (vector base ID: passport_photo_validation_ai_workflow)\n",
            "Generated TLDR: Verify if a photo is suitable for a passport by using an AI vision model and following UK government guidelines.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'passport_photo_validation_ai_workflow'.\n",
            "Batch 31 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 32/59 ---\n",
            "\n",
            "Processing file: AI Agent for realtime insights on meetings.txt\n",
            "Generated title: realtime_ai_assistant_transcription_workflow (vector base ID: realtime_ai_assistant_transcription_workflow)\n",
            "Generated TLDR: This automation workflow transcribes and organizes meeting conversations in real-time using AI assistants, storing them for easy access and analysis.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'realtime_ai_assistant_transcription_workflow'.\n",
            "\n",
            "Processing file: Automatic Background Removal for Images in Google Drive.txt\n",
            "Generated title: remove_background_google_drive_upload (vector base ID: remove_background_google_drive_upload)\n",
            "Generated TLDR: This automation workflow removes the advanced background from Google Drive images, adds padding, and uploads the modified images back to Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'remove_background_google_drive_upload'.\n",
            "\n",
            "Processing file: LINE Assistant with Google Calendar and Gmail Integration.txt\n",
            "Generated title: line_assistant_google_calendar_gmail_integration (vector base ID: line_assistant_google_calendar_gmail_integration)\n",
            "Generated TLDR: Automated assistant for LINE chatbot integrating Google Calendar and Gmail functionalities.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'line_assistant_google_calendar_gmail_integration'.\n",
            "\n",
            "Processing file: Email Subscription Service with n8n Forms, Airtable and AI.txt\n",
            "Generated title: schedule_trigger_airtable_gmail_workflowç”Ÿæˆä¸€ä¸ªæè¿°è‡ªåŠ¨åŒ–å·¥ä½œæµä¸»è¦åŠŸèƒ½çš„ç®€æ´ã€å…·ä½“å’Œç»Ÿä¸€çš„æ ‡é¢˜ã€‚ (vector base ID: schedule_trigger_airtable_gmail_workflow)\n",
            "Generated TLDR: This automation workflow sends daily, weekly, and surprise emails to subscribers based on their preferences.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'schedule_trigger_airtable_gmail_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'schedule_trigger_airtable_gmail_workflow_1'.\n",
            "\n",
            "Processing file: Narrating over a Video using Multimodal AI.txt\n",
            "Generated title: video_to_audio_voiceover_generation_using_openai (vector base ID: video_to_audio_voiceover_generation_using_openai)\n",
            "Generated TLDR: This automation workflow takes a video, extracts frames using OpenCV, generates a script with a language model, converts the script to a voiceover clip using TTS, and uploads the clip to Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'video_to_audio_voiceover_generation_using_openai'.\n",
            "Batch 32 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 33/59 ---\n",
            "\n",
            "Processing file: Daily Podcast Summary.txt\n",
            "Generated title: gmail_taddytopdaily_genre_split_out_whisper_transcribe_audio_final_data_merge_results_html_openai_schedule_request_audio_crop_get_download_link_download_cut_mp3_download_podcast_wait_if_downloads_ready_summarize_podcast_sticky_note4_if_consumer_ready (vector base ID: gmail_taddytopdaily_genre_split_out_whisper_transcribe_audio_final_data_merge_results_html_openai_schedule_request_audio_crop_get_download_link_download_cut_mp3_download_podcast_wait_if_downloads_ready_summarize_podcast_sticky_note4_if_consumer_ready)\n",
            "Generated TLDR: This automation workflow summarizes top podcasts in a specific genre and emails the summaries.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_taddytopdaily_genre_split_out_whisper_transcribe_audio_final_data_merge_results_html_openai_schedule_request_audio_crop_get_download_link_download_cut_mp3_download_podcast_wait_if_downloads_ready_summarize_podcast_sticky_note4_if_consumer_ready'.\n",
            "\n",
            "Processing file: Transform Image to Lego Style Using Line and Dall-E.txt\n",
            "Generated title: transform_image_to_lego_style_using_line_and_dall_e (vector base ID: transform_image_to_lego_style_using_line_and_dall_e)\n",
            "Generated TLDR: TLDR: This automation workflow transforms an image to Lego style by using Line webhook, Dall-E AI, and sending back the modified image via Line.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'transform_image_to_lego_style_using_line_and_dall_e'.\n",
            "\n",
            "Processing file: WordPress - AI Chatbot to enhance user experience - with Supabase and OpenAI.txt\n",
            "Generated title: agent_chat_bot_conversational_integration (vector base ID: agent_chat_bot_conversational_integration)\n",
            "Generated TLDR: This automation workflow enables chat functionality on a website using AI to retrieve and respond to user queries based on embedded content.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_chat_bot_conversational_integration_0'.\n",
            "Upserted chunk 1 as vector ID 'agent_chat_bot_conversational_integration_1'.\n",
            "\n",
            "Processing file: Vector Database as a Big Data Analysis Tool for AI Agents [3_3 - anomaly].txt\n",
            "Generated title: crop_anomaly_detection_tool (vector base ID: crop_anomaly_detection_tool)\n",
            "Generated TLDR: This automation workflow is an anomaly detection tool for crops images based on similarity to known crop classes stored in a dataset.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'crop_anomaly_detection_tool'.\n",
            "\n",
            "Processing file: AI agent that can scrape webpages.txt\n",
            "Generated title: agent_react_ai_http_request_workflow (vector base ID: agent_react_ai_http_request_workflow)\n",
            "Generated TLDR: This automation workflow fetches webpage content based on a stringified HTTP query parameter and processes it for simplicity and length constraints.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_react_ai_http_request_workflow'.\n",
            "Batch 33 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 34/59 ---\n",
            "\n",
            "Processing file: Vector Database as a Big Data Analysis Tool for AI Agents [1_3 anomaly][1_2 KNN].txt\n",
            "Generated title: batch_upload_dataset_to_qdrant (vector base ID: batch_upload_dataset_to_qdrant)\n",
            "Generated TLDR: This automation workflow uploads a batch of crop images to Qdrant for embedding and processing.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'batch_upload_dataset_to_qdrant'.\n",
            "\n",
            "Processing file: Chat with OpenAI Assistant (by adding a memory) (1).txt\n",
            "Generated title: openai_assistant_chat_workflow (vector base ID: openai_assistant_chat_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow interacts with an OpenAI Assistant, manages chat memories, aggregates messages, and outputs model results.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'openai_assistant_chat_workflow'.\n",
            "\n",
            "Processing file: Send Google analytics data to A.I. to analyze then save results in Baserow.txt\n",
            "Generated title: send_page_search_data_to_ai (vector base ID: send_page_search_data_to_ai)\n",
            "Generated TLDR: This automation workflow sends Google analytics data to A.I. and saves the results to Baserow, comparing data from different weeks.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'send_page_search_data_to_ai_0'.\n",
            "Upserted chunk 1 as vector ID 'send_page_search_data_to_ai_1'.\n",
            "\n",
            "Processing file: Intelligent Web Query and Semantic Re-Ranking Flow using Brave and Google Gemini.txt\n",
            "Generated title: intelligent_web_query_and_semantic_re_ranking_flow (vector base ID: intelligent_web_query_and_semantic_re_ranking_flow)\n",
            "Generated TLDR: This automation workflow performs intelligent web search queries and semantic result re-ranking.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'intelligent_web_query_and_semantic_re_ranking_flow_0'.\n",
            "Upserted chunk 1 as vector ID 'intelligent_web_query_and_semantic_re_ranking_flow_1'.\n",
            "\n",
            "Processing file: AI Voice Chat using Webhook, Memory Manager, OpenAI, Google Gemini & ElevenLabs.txt\n",
            "Generated title: ai_voice_chat_using_webhook_memory_manager_google_gemini_elevenlabs (vector base ID: ai_voice_chat_using_webhook_memory_manager_google_gemini_elevenlabs)\n",
            "Generated TLDR: This automation workflow processes voice messages, transcribes them using OpenAI, maintains conversation context, responds with generated audio using ElevenLabs, and incorporates the Google Gemini Chat Model.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_voice_chat_using_webhook_memory_manager_google_gemini_elevenlabs'.\n",
            "Batch 34 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 35/59 ---\n",
            "\n",
            "Processing file: AI Agent to chat with you Search Console Data, using OpenAI and Postgres.txt\n",
            "Generated title: ai_agent_to_chat_with_you_search_console_data (vector base ID: ai_agent_to_chat_with_you_search_console_data)\n",
            "Generated TLDR: This automation workflow allows an AI agent to interact with users, retrieve Search Console data, and present it in a conversational manner.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_to_chat_with_you_search_console_data_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_to_chat_with_you_search_console_data_1'.\n",
            "\n",
            "Processing file: Vector Database as a Big Data Analysis Tool for AI Agents [2_2 KNN].txt\n",
            "Generated title: multi_modal_image_classification_workflow (vector base ID: multi_modal_image_classification_workflow)\n",
            "Generated TLDR: This automation workflow classifies land types from satellite images using KNN classification and majority voting.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'multi_modal_image_classification_workflow'.\n",
            "\n",
            "Processing file: Automate Sales Meeting Prep with AI & APIFY Sent To WhatsApp.txt\n",
            "Generated title: linkedin_pre_meeting_assistant (vector base ID: linkedin_pre_meeting_assistant)\n",
            "Generated TLDR: This automation workflow generates information-dense pre-meeting notifications for a user's upcoming meetings by summarizing email correspondence and LinkedIn profiles of attendees.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'linkedin_pre_meeting_assistant_0'.\n",
            "Upserted chunk 1 as vector ID 'linkedin_pre_meeting_assistant_1'.\n",
            "Upserted chunk 2 as vector ID 'linkedin_pre_meeting_assistant_2'.\n",
            "\n",
            "Processing file: Advanced AI Demo (Presented at AI Developers #14 meetup).txt\n",
            "Generated title: assign_label_with_ai (vector base ID: assign_label_with_ai)\n",
            "Generated TLDR: This automation workflow processes emails, downloads PDFs, inserts data into a vector store, and facilitates appointment bookings with AI assistance.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'assign_label_with_ai_0'.\n",
            "Upserted chunk 1 as vector ID 'assign_label_with_ai_1'.\n",
            "\n",
            "Processing file: Upsert huge documents in a vector store with Supabase and Notion.txt\n",
            "Generated title: embeddings_openai_token_splitter_loop_over_items_question_and_answer_chain_vector_store_retriever_openai_chat_model_when_chat_message_received_schedule_trigger_sticky_note_limit_limit1_delete_old_embeddings_if_exist_get_page_blocks_default_data_loader_sticky_note1_input_reference_notion_trigger_get_updated_pages_sticky_note23_sticky_note24_sticky_note25_sticky_note26_sticky_note27_sticky_note28_supabase_vector_store1_sticky_note30_sticky_note31_supabase_vector_store_sticky_note32_sticky_note29_sticky_note33_sticky_note34_sticky_note35_concatenate_to_single_string (vector base ID: embeddings_openai_token_splitter_loop_over_items_question_and_answer_chain_vector_store_retriever_openai_chat_model_when_chat_message_received_schedule_trigger_sticky_note_limit_limit1_delete_old_embeddings_if_exist_get_page_blocks_default_data_loader_sticky_note1_input_reference_notion_trigger_get_updated_pages_sticky_note23_sticky_note24_sticky_note25_sticky_note26_sticky_note27_sticky_note28_supabase_vector_store1_sticky_note30_sticky_note31_supabase_vector_store_sticky_note32_sticky_note29_sticky_note33_sticky_note34_sticky_note35_concatenate_to_single_string)\n",
            "Generated TLDR: This automation workflow creates a chatbot that asks specific questions using context from a Notion Knowledge Base stored in a Vector Store.\n",
            "Processing 1 chunk(s).\n",
            "Error calling upsert_to_pinecone: Invalid value for `id`, length must be less than or equal to `512`\n",
            "Retrying in 2 seconds...\n",
            "Error calling upsert_to_pinecone: Invalid value for `id`, length must be less than or equal to `512`\n",
            "Retrying in 2 seconds...\n",
            "Error calling upsert_to_pinecone: Invalid value for `id`, length must be less than or equal to `512`\n",
            "Retrying in 2 seconds...\n",
            "Error calling upsert_to_pinecone: Invalid value for `id`, length must be less than or equal to `512`\n",
            "Retrying in 2 seconds...\n",
            "Error calling upsert_to_pinecone: Invalid value for `id`, length must be less than or equal to `512`\n",
            "Max retries reached.\n",
            "Failed to upsert chunk 0.\n",
            "Batch 35 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 36/59 ---\n",
            "\n",
            "Processing file: Integrating AI with Open-Meteo API for Enhanced Weather Forecasting.txt\n",
            "Generated title: integrate_ai_open_meteo_weather_forecasting (vector base ID: integrate_ai_open_meteo_weather_forecasting)\n",
            "Generated TLDR: This automation workflow integrates AI with Open-Meteo API to enhance weather forecasting.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'integrate_ai_open_meteo_weather_forecasting'.\n",
            "\n",
            "Processing file: AI web researcher for sales.txt\n",
            "Generated title: ai_company_researcher_google_sheets_update (vector base ID: ai_company_researcher_google_sheets_update)\n",
            "Generated TLDR: This automation workflow conducts company research with AI to extract information like company website, LinkedIn URL, market type, pricing plans, integrations, and more from unstructured input.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_company_researcher_google_sheets_update_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_company_researcher_google_sheets_update_1'.\n",
            "\n",
            "Processing file: Automate Customer Support Issue Resolution using AI Text Classifier.txt\n",
            "Generated title: automated_issue_resolution_workflow (vector base ID: automated_issue_resolution_workflow)\n",
            "Generated TLDR: This automation workflow automates the resolution of long-lived and forgotten JIRA issues by classifying, resolving, and closing them based on AI analysis and user interactions.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automated_issue_resolution_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'automated_issue_resolution_workflow_1'.\n",
            "\n",
            "Processing file: Hacker News Throwback Machine - See What Was Hot on This Day, Every Year!.txt\n",
            "Generated title: llm_chain_google_gemini_auto_bot (vector base ID: llm_chain_google_gemini_auto_bot)\n",
            "Generated TLDR: This automation fetches top Hacker News headlines from the front page across multiple years and categorizes them into themes with markdown hyperlinks.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'llm_chain_google_gemini_auto_bot'.\n",
            "\n",
            "Processing file: CV Resume PDF Parsing with Multimodal Vision AI.txt\n",
            "Generated title: candidate_resume_pdf_to_gemini_classification (vector base ID: candidate_resume_pdf_to_gemini_classification)\n",
            "Generated TLDR: This automation workflow converts a candidate's resume from PDF to image and assesses it using a Vision Language Model to determine if they are qualified for a desired role.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'candidate_resume_pdf_to_gemini_classification'.\n",
            "Batch 36 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 37/59 ---\n",
            "\n",
            "Processing file: Flux AI Image Generator.txt\n",
            "Generated title: route_by_style_workflow (vector base ID: route_by_style_workflow)\n",
            "Generated TLDR: This automation workflow generates AI-powered images based on different artistic styles like Hyper-Surreal Escape, Neon Fauvism, Post-Analog Glitchscape, AI Dystopia, and Vivid Pop Explosion.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'route_by_style_workflow'.\n",
            "\n",
            "Processing file: Analyse papers from Hugging Face with AI and store them in Notion.txt\n",
            "Generated title: hugging_face_to_notion_workflow (vector base ID: hugging_face_to_notion_workflow)\n",
            "Generated TLDR: This automation workflow retrieves and analyzes academic papers from Hugging Face, extracting key details and storing them in a Notion database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'hugging_face_to_notion_workflow'.\n",
            "\n",
            "Processing file: AI Data Extraction with Dynamic Prompts and Baserow.txt\n",
            "Generated title: baserow_event_router_pattern (vector base ID: baserow_event_router_pattern)\n",
            "Generated TLDR: This automation workflow allows users to update Baserow table rows based on dynamically generated values extracted from PDF files using prompts.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'baserow_event_router_pattern_0'.\n",
            "Upserted chunk 1 as vector ID 'baserow_event_router_pattern_1'.\n",
            "\n",
            "Processing file: Visualize your SQL Agent queries with OpenAI and Quickchart.io.txt\n",
            "Generated title: ai_agent_with_charts_capabilities_using_openai_structured_output_and_quickchart (vector base ID: ai_agent_with_charts_capabilities_using_openai_structured_output_and_quickchart)\n",
            "Generated TLDR: This automation workflow generates charts based on user queries processed by an AI SQL Agent.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_with_charts_capabilities_using_openai_structured_output_and_quickchart'.\n",
            "\n",
            "Processing file: Chat with local LLMs using n8n and Ollama.txt\n",
            "Generated title: chat_with_local_llms_using_n8n_and_ollama (vector base ID: chat_with_local_llms_using_n8n_and_ollama)\n",
            "Generated TLDR: This automation workflow allows users to chat with local Large Language Models (LLMs) using n8n and Ollama, seamlessly interacting through a user-friendly interface.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'chat_with_local_llms_using_n8n_and_ollama'.\n",
            "Batch 37 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 38/59 ---\n",
            "\n",
            "Processing file: Agentic Telegram AI bot with with LangChain nodes and new tools.txt\n",
            "Generated title: agent_telegram_ai_bot_langchain_integration (vector base ID: agent_telegram_ai_bot_langchain_integration)\n",
            "Generated TLDR: This automation workflow generates images with Dall-E-3 and sends them via Telegram in response to user prompts.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_telegram_ai_bot_langchain_integration'.\n",
            "\n",
            "Processing file: Automate Blog Creation in Brand Voice with AI.txt\n",
            "Generated title: content_generation_agent_ai_workflow (vector base ID: content_generation_agent_ai_workflow)\n",
            "Generated TLDR: This automation workflow uses AI to generate on-brand written content by analyzing existing published articles.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'content_generation_agent_ai_workflow'.\n",
            "\n",
            "Processing file: Remove Personally Identifiable Information (PII) from CSV Files with OpenAI.txt\n",
            "Generated title: monitor_google_drive_remove_pii_upload_drive (vector base ID: monitor_google_drive_remove_pii_upload_drive)\n",
            "Generated TLDR: This automation workflow monitors a Google Drive folder for new CSV files, removes personally identifiable information (PII) columns using OpenAI, and uploads the sanitized file back to the drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'monitor_google_drive_remove_pii_upload_drive'.\n",
            "\n",
            "Processing file: Telegram AI bot assistant_ ready-made template for voice & text messages.txt\n",
            "Generated title: telegram_ai_multi_format_chatbot (vector base ID: telegram_ai_multi_format_chatbot)\n",
            "Generated TLDR: This automation workflow processes incoming messages, transcribes audio, corrects errors, and replies accordingly using an AI chat model.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_ai_multi_format_chatbot'.\n",
            "\n",
            "Processing file: Building RAG Chatbot for Movie Recommendations with Qdrant and Open AI.txt\n",
            "Generated title: qdrant_vector_store_movie_recommender_workflow (vector base ID: qdrant_vector_store_movie_recommender_workflow)\n",
            "Generated TLDR: This automation workflow uploads movie data to a vector store, executes an AI agent to recommend movies, and retrieves recommended movie metadata.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'qdrant_vector_store_movie_recommender_workflow'.\n",
            "Batch 38 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 39/59 ---\n",
            "\n",
            "Processing file: CV Screening with OpenAI.txt\n",
            "Generated title: extract_file_download_openai_analyze_cv_parsed_json (vector base ID: extract_file_download_openai_analyze_cv_parsed_json)\n",
            "Generated TLDR: This automation workflow automates the initial screening of CVs by extracting and analyzing text data using OpenAI and storing the results in a structured format.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'extract_file_download_openai_analyze_cv_parsed_json'.\n",
            "\n",
            "Processing file: Chat Assistant (OpenAI assistant) with Postgres Memory And API Calling Capabalities.txt\n",
            "Generated title: chatbot_openai_interaction (vector base ID: chatbot_openai_interaction)\n",
            "Generated TLDR: This automation workflow processes chat inputs, interacts with OpenAI, and stores chat memory in a PostgreSQL database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'chatbot_openai_interaction'.\n",
            "\n",
            "Processing file: Ultimate Scraper Workflow for n8n.txt\n",
            "Generated title: selenium_ultimate_scraper_workflow (vector base ID: selenium_ultimate_scraper_workflow)\n",
            "Generated TLDR: This automation workflow scrapes data from websites using Selenium with session management and AI analysis.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'selenium_ultimate_scraper_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'selenium_ultimate_scraper_workflow_1'.\n",
            "Upserted chunk 2 as vector ID 'selenium_ultimate_scraper_workflow_2'.\n",
            "\n",
            "Processing file: Create a Google Analytics Data Report with AI and sent it to E-Mail and Telegram.txt\n",
            "Generated title: google_analytics_weekly_report_workflow (vector base ID: google_analytics_weekly_report_workflow)\n",
            "Generated TLDR: This automation generates a weekly report using Google Analytics data, summarizing key metrics and sending the report via email and possibly as a Telegram message.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_analytics_weekly_report_workflow'.\n",
            "\n",
            "Processing file: Zoom AI Meeting Assistant creates mail summary, ClickUp tasks and follow-up call.txt\n",
            "Generated title: zoom_ai_meeting_assistant_workflow (vector base ID: zoom_ai_meeting_assistant_workflow)\n",
            "Generated TLDR: This automation workflow summarizes Zoom meeting transcripts and creates tasks and follow-up calls based on the meeting content.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'zoom_ai_meeting_assistant_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'zoom_ai_meeting_assistant_workflow_1'.\n",
            "Batch 39 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 40/59 ---\n",
            "\n",
            "Processing file: Generate SQL queries from schema only - AI-powered.txt\n",
            "Generated title: generate_sql_queries_from_schema_only_ai_powered (vector base ID: generate_sql_queries_from_schema_only_ai_powered)\n",
            "Generated TLDR: Generate SQL queries from database schema using AI-powered chat model and respond to user queries with SQL results.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_sql_queries_from_schema_only_ai_powered'.\n",
            "\n",
            "Processing file: Qualifying Appointment Requests with AI & n8n Forms.txt\n",
            "Generated title: appointment_scheduling_workflow_with_ai_integration (vector base ID: appointment_scheduling_workflow_with_ai_integration)\n",
            "Generated TLDR: This automation workflow schedules appointments, qualifies inquiries via AI, and triggers approval processes for confirmed appointments.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'appointment_scheduling_workflow_with_ai_integration_0'.\n",
            "Upserted chunk 1 as vector ID 'appointment_scheduling_workflow_with_ai_integration_1'.\n",
            "\n",
            "Processing file: AI Agent to chat with Supabase_PostgreSQL DB.txt\n",
            "Generated title: ai_agent_db_conversation (vector base ID: ai_agent_db_conversation)\n",
            "Generated TLDR: This automation workflow enables users to interact conversationally with a Supabase database via an AI agent, simplifying data retrieval and analysis with dynamically generated SQL queries.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_db_conversation'.\n",
            "\n",
            "Processing file: Generate SEO Seed Keywords Using AI.txt\n",
            "Generated title: generate_seed_keywords_icp_ai_agent_ai_api_database (vector base ID: generate_seed_keywords_icp_ai_agent_ai_api_database)\n",
            "Generated TLDR: This automation workflow generates SEO seed keywords using AI based on an ideal customer profile.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_seed_keywords_icp_ai_agent_ai_api_database'.\n",
            "\n",
            "Processing file: AI-Powered Candidate Shortlisting Automation for ERPNext.txt\n",
            "Generated title: recruitment_ai_agent_workflow (vector base ID: recruitment_ai_agent_workflow)\n",
            "Generated TLDR: This automation workflow is for processing job applicant data, extracting relevant information from resumes, analyzing candidate suitability using an AI agent, and updating applicant status in ERPNext based on evaluation results.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'recruitment_ai_agent_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'recruitment_ai_agent_workflow_1'.\n",
            "Batch 40 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 41/59 ---\n",
            "\n",
            "Processing file: Generate 9_16 Images from Content and Brand Guidelines.txt\n",
            "Generated title: content_to_9_16_aspect_image_generator_v1 (vector base ID: content_to_9_16_aspect_image_generator_v1)\n",
            "Generated TLDR: This automation workflow generates 9:16 aspect ratio images from blog post content for short form video creation.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'content_to_9_16_aspect_image_generator_v1_0'.\n",
            "Upserted chunk 1 as vector ID 'content_to_9_16_aspect_image_generator_v1_1'.\n",
            "Upserted chunk 2 as vector ID 'content_to_9_16_aspect_image_generator_v1_2'.\n",
            "\n",
            "Processing file: AI Agent for project management and meetings with Airtable and Fireflies.txt\n",
            "Generated title: ai_agent_fireflies_airtable_google_calendar (vector base ID: ai_agent_fireflies_airtable_google_calendar)\n",
            "Generated TLDR: This automation workflow manages action items from meetings by generating tasks from meeting transcripts and notifying participants of their responsibilities.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_fireflies_airtable_google_calendar'.\n",
            "\n",
            "Processing file: AI-Driven Lead Management and Inquiry Automation with ERPNext & n8n.txt\n",
            "Generated title: ai_driven_lead_management_inquiry_automation_erpnext_n8n (vector base ID: ai_driven_lead_management_inquiry_automation_erpnext_n8n)\n",
            "Generated TLDR: TLDR: This automation uses AI to analyze new leads, categorize them, and generate professional email notifications for relevant inquiries.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_driven_lead_management_inquiry_automation_erpnext_n8n_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_driven_lead_management_inquiry_automation_erpnext_n8n_1'.\n",
            "\n",
            "Processing file: Spot Workplace Discrimination Patterns with AI.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20162 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20162 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20162 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20162 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20162 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: Spot Workplace Discrimination Patterns with AI.txt (vector base ID: Spot Workplace Discrimination Patterns with AI.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20126 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20126 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20126 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20126 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 20126 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 4 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'Spot Workplace Discrimination Patterns with AI.txt_0'.\n",
            "Upserted chunk 1 as vector ID 'Spot Workplace Discrimination Patterns with AI.txt_1'.\n",
            "Upserted chunk 2 as vector ID 'Spot Workplace Discrimination Patterns with AI.txt_2'.\n",
            "Upserted chunk 3 as vector ID 'Spot Workplace Discrimination Patterns with AI.txt_3'.\n",
            "\n",
            "Processing file: ðŸ“š Auto-generate documentation for n8n workflows with GPT and Docsify.txt\n",
            "Generated title: docsify_example (vector base ID: docsify_example)\n",
            "Generated TLDR: This automation workflow generates and serves documentation using Docsify with features like creating, editing, and saving Markdown files along with workflow overview tables and navigation from a webhook-triggered interface.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'docsify_example_0'.\n",
            "Upserted chunk 1 as vector ID 'docsify_example_1'.\n",
            "Upserted chunk 2 as vector ID 'docsify_example_2'.\n",
            "Batch 41 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 42/59 ---\n",
            "\n",
            "Processing file: AI Youtube Trend Finder Based On Niche.txt\n",
            "Generated title: ai_agent_youtube_trending_videos_analysis (vector base ID: ai_agent_youtube_trending_videos_analysis)\n",
            "Generated TLDR: This automation helps YouTube creators find trending videos based on a specific niche by using AI to search, analyze, and provide valuable insights on trending content.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_youtube_trending_videos_analysis'.\n",
            "\n",
            "Processing file: AI-Generated Summary Block for WordPress Posts.txt\n",
            "Generated title: ai_generated_summary_wordpress_google_sheets_slack (vector base ID: ai_generated_summary_wordpress_google_sheets_slack)\n",
            "Generated TLDR: Automates adding AI-generated summaries to WordPress posts, classifying content and updating Google Sheets and notifying Slack accordingly.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_generated_summary_wordpress_google_sheets_slack_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_generated_summary_wordpress_google_sheets_slack_1'.\n",
            "\n",
            "Processing file: Auto Categorise Outlook Emails with AI.txt\n",
            "Generated title: auto_categorise_outlook_emails_with_ai (vector base ID: auto_categorise_outlook_emails_with_ai)\n",
            "Generated TLDR: This automation workflow categorizes Outlook emails with AI based on defined criteria.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'auto_categorise_outlook_emails_with_ai_0'.\n",
            "Upserted chunk 1 as vector ID 'auto_categorise_outlook_emails_with_ai_1'.\n",
            "\n",
            "Processing file: âœ¨ Vision-Based AI Agent Scraper - with Google Sheets, ScrapingBee, and Gemini.txt\n",
            "Generated title: vision_based_ai_agent_scraper_with_google_sheets_scrapingbee_and_gemini (vector base ID: vision_based_ai_agent_scraper_with_google_sheets_scrapingbee_and_gemini)\n",
            "Generated TLDR: This automation workflow leverages a vision-based AI Agent with Google Sheets, ScrapingBee, and Gemini model to extract structured data from webpages, primarily using screenshots for extraction with switch to HTML scraping when necessary, optimized for e-commerce scraping.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'vision_based_ai_agent_scraper_with_google_sheets_scrapingbee_and_gemini_0'.\n",
            "Upserted chunk 1 as vector ID 'vision_based_ai_agent_scraper_with_google_sheets_scrapingbee_and_gemini_1'.\n",
            "\n",
            "Processing file: Respond to WhatsApp Messages with AI Like a Pro!.txt\n",
            "Generated title: whatsapp_chatbot_agent (vector base ID: whatsapp_chatbot_agent)\n",
            "Generated TLDR: This automation workflow is a WhatsApp chatbot that handles different message types using AI to generate responses and send them back to the user.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'whatsapp_chatbot_agent_0'.\n",
            "Upserted chunk 1 as vector ID 'whatsapp_chatbot_agent_1'.\n",
            "Batch 42 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 43/59 ---\n",
            "\n",
            "Processing file: Conversational Interviews with AI Agents and n8n Forms.txt\n",
            "Generated title: start_interview_with_ai_agent (vector base ID: start_interview_with_ai_agent)\n",
            "Generated TLDR: This automation workflow conducts AI-powered user interviews on the topic of the UK Practical Driving Test, recording questions and answers in a Google Sheet for later analysis.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'start_interview_with_ai_agent_0'.\n",
            "Upserted chunk 1 as vector ID 'start_interview_with_ai_agent_1'.\n",
            "Upserted chunk 2 as vector ID 'start_interview_with_ai_agent_2'.\n",
            "\n",
            "Processing file: Learn Anything from HN - Get Top Resource Recommendations from Hacker News.txt\n",
            "Generated title: search_ask_hn_resources_workflow (vector base ID: search_ask_hn_resources_workflow)\n",
            "Generated TLDR: This automation workflow finds the top resources recommended on HackerNews for learning a specified topic and sends them via email in Markdown format.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'search_ask_hn_resources_workflow'.\n",
            "\n",
            "Processing file: Obsidian Notes Read Aloud using AI_ Available as a Podcast Feed.txt\n",
            "Generated title: obsidian_notes_read_aloud_to_podcast_feed (vector base ID: obsidian_notes_read_aloud_to_podcast_feed)\n",
            "Generated TLDR: This automation converts notes to audio, generates concise podcast descriptions, appends data to Google Sheets, and creates an RSS feed from the collected data.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'obsidian_notes_read_aloud_to_podcast_feed_0'.\n",
            "Upserted chunk 1 as vector ID 'obsidian_notes_read_aloud_to_podcast_feed_1'.\n",
            "\n",
            "Processing file: AI agent chat.txt\n",
            "Generated title: ai_agent_workflow (vector base ID: ai_agent_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow utilizes OpenAI and SerpAPI to generate responses based on chat messages received by an AI Agent.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_workflow'.\n",
            "\n",
            "Processing file: Siri AI Agent_ Apple Shortcuts powered voice template.txt\n",
            "Generated title: ai_agent_apple_shortcut_integration (vector base ID: ai_agent_apple_shortcut_integration)\n",
            "Generated TLDR: TLDR: This automation workflow enables triggering an n8n AI Agent via Apple Shortcuts using spoken commands, processing inputs, and delivering responses via Siri.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_apple_shortcut_integration'.\n",
            "Batch 43 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 44/59 ---\n",
            "\n",
            "Processing file: Daily meetings summarization with Gemini AI.txt\n",
            "Generated title: schedule_trigger_calendar_ai_geminichat_googlecalendar (vector base ID: schedule_trigger_calendar_ai_geminichat_googlecalendar)\n",
            "Generated TLDR: TLDR: This automation workflow summarizes daily meetings using AI and sends the response back to a Slack channel.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'schedule_trigger_calendar_ai_geminichat_googlecalendar'.\n",
            "\n",
            "Processing file: Microsoft Outlook AI Email Assistant with contact support from Monday and Airtable.txt\n",
            "Generated title: microsoft_outlook_ai_email_assistant (vector base ID: microsoft_outlook_ai_email_assistant)\n",
            "Generated TLDR: This automation workflow categorizes and prioritizes incoming emails using an AI email assistant.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'microsoft_outlook_ai_email_assistant_0'.\n",
            "Upserted chunk 1 as vector ID 'microsoft_outlook_ai_email_assistant_1'.\n",
            "\n",
            "Processing file: Extract text from PDF and image using Vertex AI (Gemini) into CSV.txt\n",
            "Generated title: extract_text_from_pdf_and_image_into_csv_using_vertex_ai_gemini (vector base ID: extract_text_from_pdf_and_image_into_csv_using_vertex_ai_gemini)\n",
            "Generated TLDR: This automation extracts text data from PDF and images, processes and categorizes it using A.I., and stores the results as CSV files in Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'extract_text_from_pdf_and_image_into_csv_using_vertex_ai_gemini'.\n",
            "\n",
            "Processing file: Summarize YouTube Videos from Transcript.txt\n",
            "Generated title: summarize_youtube_videos_workflow (vector base ID: summarize_youtube_videos_workflow)\n",
            "Generated TLDR: Automate the summarization of YouTube videos using AI to create concise insights for content creators and researchers.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'summarize_youtube_videos_workflow'.\n",
            "\n",
            "Processing file: Notion AI Assistant Generator.txt\n",
            "Generated title: generate_new_workflow_for_specific_notion_db_schema (vector base ID: generate_new_workflow_for_specific_notion_db_schema)\n",
            "Generated TLDR: Generates an AI Assistant chatbot workflow for a specific Notion database URL based on a template.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_new_workflow_for_specific_notion_db_schema_0'.\n",
            "Upserted chunk 1 as vector ID 'generate_new_workflow_for_specific_notion_db_schema_1'.\n",
            "Batch 44 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 45/59 ---\n",
            "\n",
            "Processing file: Auto-Categorize blog posts in wordpress using A.I..txt\n",
            "Generated title: auto_categorize_wordpress_template_workflow (vector base ID: auto_categorize_wordpress_template_workflow)\n",
            "Generated TLDR: This automation workflow categorizes WordPress posts using AI for efficient content organization.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'auto_categorize_wordpress_template_workflow'.\n",
            "\n",
            "Processing file: Using External Workflows as Tools in n8n.txt\n",
            "Generated title: get_a_web_page (vector base ID: get_a_web_page)\n",
            "Generated TLDR: This automation workflow scrapes a web page using FireCrawl, edits the response fields, and provides instructions on how to use the crawled data.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'get_a_web_page'.\n",
            "\n",
            "Processing file: BambooHR AI-Powered Company Policies and Benefits Chatbot.txt\n",
            "Generated title: ai_hr_benefits_company_policies_chatbot (vector base ID: ai_hr_benefits_company_policies_chatbot)\n",
            "Generated TLDR: This automation workflow is an AI-powered chatbot that retrieves and provides information on company policies and benefits from various sources based on user queries.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_hr_benefits_company_policies_chatbot_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_hr_benefits_company_policies_chatbot_1'.\n",
            "\n",
            "Processing file: Scrape and summarize webpages with AI.txt\n",
            "Generated title: scrape_paul_graham_essays_summarize (vector base ID: scrape_paul_graham_essays_summarize)\n",
            "Generated TLDR: Scrape latest Paul Graham essays, summarize them with GPT, and generate a chat model response using OpenAI.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'scrape_paul_graham_essays_summarize'.\n",
            "\n",
            "Processing file: Extract personal data with self-hosted LLM Mistral NeMo.txt\n",
            "Generated title: chat_message_to_json_output_extraction (vector base ID: chat_message_to_json_output_extraction)\n",
            "Generated TLDR: This automation workflow extracts personal data from chat messages using a self-hosted LLM Mistral NeMo model.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'chat_message_to_json_output_extraction'.\n",
            "Batch 45 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 46/59 ---\n",
            "\n",
            "Processing file: ðŸ‹DeepSeek V3 Chat & R1 Reasoning Quick Start.txt\n",
            "Generated title: deapseek_chat_reasoning_quick_start (vector base ID: deapseek_chat_reasoning_quick_start)\n",
            "Generated TLDR: This automation workflow facilitates a conversational agent interaction using the DeepSeek and Ollama models for language processing.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'deapseek_chat_reasoning_quick_start'.\n",
            "\n",
            "Processing file: Make OpenAI Citation for File Retrieval RAG.txt\n",
            "Generated title: make_openai_citation_file_retrieval_rag (vector base ID: make_openai_citation_file_retrieval_rag)\n",
            "Generated TLDR: Generate OpenAI citations for file retrieval using N8N automation workflow.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'make_openai_citation_file_retrieval_rag'.\n",
            "\n",
            "Processing file: Automated End-to-End Fine-Tuning of OpenAI Models with Google Drive Integration.txt\n",
            "Generated title: fine_tuning_google_drive_openai_chat_assignment (vector base ID: fine_tuning_google_drive_openai_chat_assignment)\n",
            "Generated TLDR: TLDR: This automation workflow finetunes OpenAI models using Google Drive to upload data and triggers AI chat interactions.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'fine_tuning_google_drive_openai_chat_assignment'.\n",
            "\n",
            "Processing file: AI Data Extraction with Dynamic Prompts and Airtable.txt\n",
            "Generated title: airtable_ai_data_extraction_DYNAMIC_PROMPTS_workflow (vector base ID: airtable_ai_data_extraction_DYNAMIC_PROMPTS_workflow)\n",
            "Generated TLDR: This automation workflow dynamically extracts data from PDF files uploaded to Airtable using AI and updates the corresponding records with the extracted values.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'airtable_ai_data_extraction_DYNAMIC_PROMPTS_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'airtable_ai_data_extraction_DYNAMIC_PROMPTS_workflow_1'.\n",
            "\n",
            "Processing file: AI Agent to chat with Airtable and analyze data.txt\n",
            "Generated title: ai_agent_chat_airtable_analysis (vector base ID: ai_agent_chat_airtable_analysis)\n",
            "Generated TLDR: TLDR: This automation workflow enables an AI agent to facilitate chat interactions over Airtable data, including retrieving records, executing math functions, and generating map images.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chat_airtable_analysis_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_chat_airtable_analysis_1'.\n",
            "Batch 46 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 47/59 ---\n",
            "\n",
            "Processing file: AI-Powered Information Monitoring with OpenAI, Google Sheets, Jina AI and Slack.txt\n",
            "Generated title: ai_powered_information_monitoring_with_openai_google_sheets_jina_ai_slack (vector base ID: ai_powered_information_monitoring_with_openai_google_sheets_jina_ai_slack)\n",
            "Generated TLDR: TLDR: This automation workflow monitors RSS feeds, classifies articles on AI topics, summarizes relevant articles using OpenAI and Jina AI, and posts them to Slack.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_powered_information_monitoring_with_openai_google_sheets_jina_ai_slack_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_powered_information_monitoring_with_openai_google_sheets_jina_ai_slack_1'.\n",
            "\n",
            "Processing file: Personal Shopper Chatbot for WooCommerce with RAG using Google Drive and openAI.txt\n",
            "Generated title: ai_agent_shop_workflow (vector base ID: ai_agent_shop_workflow)\n",
            "Generated TLDR: TLDR: This automation workflow uses AI tools to analyze chat messages, extract information about user requests for products or general store inquiries, and filter products on WooCommerce accordingly.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_shop_workflow'.\n",
            "\n",
            "Processing file: AI Agent To Chat With Files In Supabase Storage.txt\n",
            "Generated title: ai_agent_supabase_storage_interaction (vector base ID: ai_agent_supabase_storage_interaction)\n",
            "Generated TLDR: This automation workflow automates processing and querying text and PDF files stored in Supabase using vectorized data and AI-powered interactions.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_supabase_storage_interaction'.\n",
            "\n",
            "Processing file: Notion to Pinecone Vector Store Integration.txt\n",
            "Generated title: notion_to_vector_store_dim768_workflow (vector base ID: notion_to_vector_store_dim768_workflow)\n",
            "Generated TLDR: This automation workflow extracts text content from Notion pages, generates text embeddings using Google Gemini, and stores them in a Vector Store.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'notion_to_vector_store_dim768_workflow'.\n",
            "\n",
            "Processing file: AI-Powered RAG Workflow For Stock Earnings Report Analysis.txt\n",
            "Generated title: ai_agent_google_financial_report_generation_workflow (vector base ID: ai_agent_google_financial_report_generation_workflow)\n",
            "Generated TLDR: This automation workflow generates a financial report on Google's last three quarters' earnings based on semantic search and analysis of PDF documents.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_google_financial_report_generation_workflow'.\n",
            "Batch 47 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 48/59 ---\n",
            "\n",
            "Processing file: Building Your First WhatsApp Chatbot (1).txt\n",
            "Generated title: sales_agent_whatsapp_chatbot (vector base ID: sales_agent_whatsapp_chatbot)\n",
            "Generated TLDR: This automation workflow creates a WhatsApp chatbot for a company selling Yamaha Powered Loudspeakers, providing user assistance based on a product brochure and AI responses.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'sales_agent_whatsapp_chatbot'.\n",
            "\n",
            "Processing file: Angie, Personal AI Assistant with Telegram Voice and Text.txt\n",
            "Generated title: google_calendar_openai_gmail_telegram_tasks_contacts (vector base ID: google_calendar_openai_gmail_telegram_tasks_contacts)\n",
            "Generated TLDR: This automation workflow processes incoming events from a Telegram account, transcribes voice messages, fetches unread emails from Gmail, interacts with Google Calendar, and uses AI models to assist users with various tasks.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_calendar_openai_gmail_telegram_tasks_contacts'.\n",
            "\n",
            "Processing file: Query Perplexity AI from your n8n workflows.txt\n",
            "Generated title: perplexity_request_clean_output_workflow (vector base ID: perplexity_request_clean_output_workflow)\n",
            "Generated TLDR: This automation workflow generates responses to prompts using the Sonar model from Perplexity AI.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'perplexity_request_clean_output_workflow'.\n",
            "\n",
            "Processing file: AI agent for Instagram DM_inbox. Manychat + Open AI integration.txt\n",
            "Generated title: ai_agent_chat_gpt_respond_webhook_instagram (vector base ID: ai_agent_chat_gpt_respond_webhook_instagram)\n",
            "Generated TLDR: This automation workflow generates AI responses for Instagram messages using ChatGPT model.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chat_gpt_respond_webhook_instagram'.\n",
            "\n",
            "Processing file: Fetch Dynamic Prompts from GitHub and Auto-Populate n8n Expressions in Prompt.txt\n",
            "Generated title: load_prompts_from_github_repo_and_auto_populate_n8n_expressions (vector base ID: load_prompts_from_github_repo_and_auto_populate_n8n_expressions)\n",
            "Generated TLDR: This automation workflow loads prompts from a Github repository and auto-populates n8n expressions based on specified variables.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'load_prompts_from_github_repo_and_auto_populate_n8n_expressions'.\n",
            "Batch 48 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 49/59 ---\n",
            "\n",
            "Processing file: AI-Powered Social Media Amplifier.txt\n",
            "Generated title: social_media_ai_agent_telegram (vector base ID: social_media_ai_agent_telegram)\n",
            "Generated TLDR: Automate posting of trending GitHub discussions to Twitter and LinkedIn using AI-generated content.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'social_media_ai_agent_telegram_0'.\n",
            "Upserted chunk 1 as vector ID 'social_media_ai_agent_telegram_1'.\n",
            "\n",
            "Processing file: ðŸ” Perplexity Research to HTML_ AI-Powered Content Creation.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43928 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43928 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43928 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43928 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43928 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: ðŸ” Perplexity Research to HTML_ AI-Powered Content Creation.txt (vector base ID:  Perplexity Research to HTML_ AI-Powered Content Creation.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43892 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43892 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43892 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43892 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 43892 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 8 chunk(s).\n",
            "Upserted chunk 0 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_0'.\n",
            "Upserted chunk 1 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_1'.\n",
            "Upserted chunk 2 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_2'.\n",
            "Upserted chunk 3 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_3'.\n",
            "Upserted chunk 4 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_4'.\n",
            "Upserted chunk 5 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_5'.\n",
            "Upserted chunk 6 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_6'.\n",
            "Upserted chunk 7 as vector ID ' Perplexity Research to HTML_ AI-Powered Content Creation.txt_7'.\n",
            "\n",
            "Processing file: Summarize the New Documents from Google Drive and Save Summary in Google Sheet.txt\n",
            "Generated title: google_doc_summarizer_to_google_sheets (vector base ID: google_doc_summarizer_to_google_sheets)\n",
            "Generated TLDR: This automation workflow streamlines the process of summarizing recently uploaded Google Docs using AI and storing the summaries in Google Sheets.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'google_doc_summarizer_to_google_sheets'.\n",
            "\n",
            "Processing file: RAG Chatbot for Company Documents using Google Drive and Gemini.txt\n",
            "Generated title: rag_workflow_for_company_documents_google_drive_ai_agent_company_documents_tool_embedding_gemini_chat_restrictive_character_splitter_vector_store_tool_drive_integration (vector base ID: rag_workflow_for_company_documents_google_drive_ai_agent_company_documents_tool_embedding_gemini_chat_restrictive_character_splitter_vector_store_tool_drive_integration)\n",
            "Generated TLDR: This automation workflow retrieves information from company documents stored in Google Drive to answer employee questions based on company policies.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'rag_workflow_for_company_documents_google_drive_ai_agent_company_documents_tool_embedding_gemini_chat_restrictive_character_splitter_vector_store_tool_drive_integration'.\n",
            "\n",
            "Processing file: AI Fitness Coach Strava Data Analysis and Personalized Training Insights.txt\n",
            "Generated title: strava_trigger_agent_fitness_coach_convert_to_html (vector base ID: strava_trigger_agent_fitness_coach_convert_to_html)\n",
            "Generated TLDR: This automation workflow analyzes Strava activity data to provide personalized coaching advice for improving performance in running, swimming, and cycling.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'strava_trigger_agent_fitness_coach_convert_to_html'.\n",
            "Batch 49 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 50/59 ---\n",
            "\n",
            "Processing file: âš¡AI-Powered YouTube Video Summarization & Analysis.txt\n",
            "Generated title: webhook_youtube_transcript_telegram_response (vector base ID: webhook_youtube_transcript_telegram_response)\n",
            "Generated TLDR: This automation workflow summarizes and analyzes YouTube video transcripts and sends a structured summary via Telegram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'webhook_youtube_transcript_telegram_response'.\n",
            "\n",
            "Processing file: ðŸ¤– Telegram Messaging Agent for Text_Audio_Images.txt\n",
            "Generated title: telegram_messaging_agent_audio_image_classification (vector base ID: telegram_messaging_agent_audio_image_classification)\n",
            "Generated TLDR: This automation workflow processes incoming messages from Telegram, handling text, audio, and image data by analyzing, transcribing, and routing them accordingly.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'telegram_messaging_agent_audio_image_classification_0'.\n",
            "Upserted chunk 1 as vector ID 'telegram_messaging_agent_audio_image_classification_1'.\n",
            "\n",
            "Processing file: Chat with GitHub API Documentation_ RAG-Powered Chatbot with Pinecone & OpenAI.txt\n",
            "Generated title: rag_workflow_github_api_chatbot_with_openai_pinecone (vector base ID: rag_workflow_github_api_chatbot_with_openai_pinecone)\n",
            "Generated TLDR: This automation workflow generates embeddings for GitHub API OpenAPI specifications and uses them to power a chat interface that can answer questions about the API.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'rag_workflow_github_api_chatbot_with_openai_pinecone'.\n",
            "\n",
            "Processing file: Extract and process information directly from PDF using Claude and Gemini.txt\n",
            "Generated title: extract_data_from_pdf_with_claude_3_5_sonnet_or_gemini_2_0_flash (vector base ID: extract_data_from_pdf_with_claude_3_5_sonnet_or_gemini_2_0_flash)\n",
            "Generated TLDR: This automation workflow extracts data from a PDF using Claude 3.5 Sonnet and Gemini 2.0 Flash for comparison.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'extract_data_from_pdf_with_claude_3_5_sonnet_or_gemini_2_0_flash'.\n",
            "\n",
            "Processing file: Complete business WhatsApp AI-Powered RAG Chatbot using OpenAI.txt\n",
            "Generated title: business_whatsapp_ai_rag_chatbot (vector base ID: business_whatsapp_ai_rag_chatbot)\n",
            "Generated TLDR: This automation workflow implements a Business WhatsApp AI RAG Chatbot that responds to user messages, provides product information, troubleshooting tips, and general support using AI-powered conversational agents.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'business_whatsapp_ai_rag_chatbot'.\n",
            "Batch 50 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 51/59 ---\n",
            "\n",
            "Processing file: Hacker News to Video Content.txt\n",
            "Generated title: hacker_news_to_video_template (vector base ID: hacker_news_to_video_template)\n",
            "Generated TLDR: This automation workflow generates videos based on articles from Hacker News and summarizes and analyzes their content.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'hacker_news_to_video_template_0'.\n",
            "Upserted chunk 1 as vector ID 'hacker_news_to_video_template_1'.\n",
            "\n",
            "Processing file: ðŸŽ¨ Interactive Image Editor with FLUX.1 Fill Tool for Inpainting.txt\n",
            "Generated title: flux_fill_editor_image_processing_workflow (vector base ID: flux_fill_editor_image_processing_workflow)\n",
            "Generated TLDR: This automation workflow generates edited images using the FLUX-Fill tool based on user input prompts and settings.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'flux_fill_editor_image_processing_workflow'.\n",
            "\n",
            "Processing file: API Schema Extractor.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23574 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23574 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23574 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23574 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23574 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: API Schema Extractor.txt (vector base ID: API Schema Extractor.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23538 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23538 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23538 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23538 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 23538 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 4 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'API Schema Extractor.txt_0'.\n",
            "Upserted chunk 1 as vector ID 'API Schema Extractor.txt_1'.\n",
            "Upserted chunk 2 as vector ID 'API Schema Extractor.txt_2'.\n",
            "Upserted chunk 3 as vector ID 'API Schema Extractor.txt_3'.\n",
            "\n",
            "Processing file: Basic Automatic Gmail Email Labelling with OpenAI and Gmail API.txt\n",
            "Generated title: gmail_label_auto_categorization (vector base ID: gmail_label_auto_categorization)\n",
            "Generated TLDR: Automatically categorize incoming emails in Gmail based on existing labels or create new labels if needed.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'gmail_label_auto_categorization'.\n",
            "\n",
            "Processing file: Analyze tradingview.com charts with Chrome extension, N8N and OpenAI.txt\n",
            "Generated title: webhook_openai_respond_to_webhook (vector base ID: webhook_openai_respond_to_webhook)\n",
            "Generated TLDR: TLDR: This automation workflow uses OpenAI to analyze stock or crypto currency charts and provide insights in simple language based on technical indicators, responding to a webhook trigger.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'webhook_openai_respond_to_webhook'.\n",
            "Batch 51 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 52/59 ---\n",
            "\n",
            "Processing file: AI Powered Web Scraping with Jina, Google Sheets and OpenAI _ the EASY way.txt\n",
            "Generated title: jina_fetch_extract_google_sheet (vector base ID: jina_fetch_extract_google_sheet)\n",
            "Generated TLDR: This automation workflow scrapes book data from a website, extracts relevant information using an AI model, and saves it to a Google Sheet.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'jina_fetch_extract_google_sheet'.\n",
            "\n",
            "Processing file: UTM Link Creator & QR Code Generator with Scheduled Google Analytics Reports.txt\n",
            "Generated title: utm_link_creator_qr_code_generator_marketing_analytics_workflow (vector base ID: utm_link_creator_qr_code_generator_marketing_analytics_workflow)\n",
            "Generated TLDR: This automation workflow creates UTM links with parameters, stores them in a database, generates QR codes, and schedules Google Analytics reports.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'utm_link_creator_qr_code_generator_marketing_analytics_workflow'.\n",
            "\n",
            "Processing file: AI Social Media Caption Creator creates social media post captions in Airtable.txt\n",
            "Generated title: ai_social_media_caption_creator_workflow (vector base ID: ai_social_media_caption_creator_workflow)\n",
            "Generated TLDR: This automation workflow automatically creates social media post captions using AI and background information stored in Airtable.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_social_media_caption_creator_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_social_media_caption_creator_workflow_1'.\n",
            "\n",
            "Processing file: Use OpenRouter in n8n versions _1.78.txt\n",
            "Generated title: use_any_llm_model_via_openrouter (vector base ID: use_any_llm_model_via_openrouter)\n",
            "Generated TLDR: TLDR: This automation workflow allows users to use any LLM-Model via OpenRouter for fully configurable model functionality.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'use_any_llm_model_via_openrouter'.\n",
            "\n",
            "Processing file: Building Your First WhatsApp Chatbot.txt\n",
            "Generated title: sales_ai_agent_responds_to_customers (vector base ID: sales_ai_agent_responds_to_customers)\n",
            "Generated TLDR: This automation workflow creates a WhatsApp chatbot powered by an AI sales agent to help users navigate a product catalog.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'sales_ai_agent_responds_to_customers'.\n",
            "Batch 52 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 53/59 ---\n",
            "\n",
            "Processing file: HR Job Posting and Evaluation with AI.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17888 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17888 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17888 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17888 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17888 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: HR Job Posting and Evaluation with AI.txt (vector base ID: HR Job Posting and Evaluation with AI.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17852 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17852 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17852 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17852 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17852 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 3 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'HR Job Posting and Evaluation with AI.txt_0'.\n",
            "Upserted chunk 1 as vector ID 'HR Job Posting and Evaluation with AI.txt_1'.\n",
            "Upserted chunk 2 as vector ID 'HR Job Posting and Evaluation with AI.txt_2'.\n",
            "\n",
            "Processing file: Extract license plate number from image uploaded via an n8n form.txt\n",
            "Generated title: image_license_plate_extraction (vector base ID: image_license_plate_extraction)\n",
            "Generated TLDR: This automation workflow extracts the license plate number from an uploaded image and presents the extracted information.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'image_license_plate_extraction'.\n",
            "\n",
            "Processing file: AI Agent _ Google calendar assistant using OpenAI.txt\n",
            "Generated title: ai_agent_google_calendar_assistant_using_openai (vector base ID: ai_agent_google_calendar_assistant_using_openai)\n",
            "Generated TLDR: This automation workflow acts as a Google Calendar assistant AI agent that can retrieve and create events based on chat input.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_google_calendar_assistant_using_openai'.\n",
            "\n",
            "Processing file: Modular & Customizable AI-Powered Email Routing_ Text Classifier for eCommerce.txt\n",
            "Generated title: contact_form_text_classifier_for_ecommerce (vector base ID: contact_form_text_classifier_for_ecommerce)\n",
            "Generated TLDR: Automates the classification and handling of contact form submissions for eCommerce businesses or customer support teams.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'contact_form_text_classifier_for_ecommerce'.\n",
            "\n",
            "Processing file: Detect hallucinations using specialised Ollama model bespoke-minicheck.txt\n",
            "Generated title: code_split_ollama_chat_workflow (vector base ID: code_split_ollama_chat_workflow)\n",
            "Generated TLDR: This automation workflow splits input text into sentences, performs fact-checking using specialized models, and aggregates the results.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'code_split_ollama_chat_workflow'.\n",
            "Batch 53 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 54/59 ---\n",
            "\n",
            "Processing file: Open Deep Research - AI-Powered Autonomous Research Workflow.txt\n",
            "Generated title: chat_message_trigger_generate_search_queries_agent_fetch_wikipedia_information_extract_relevant_context_generate_comprehensive_research_report (vector base ID: chat_message_trigger_generate_search_queries_agent_fetch_wikipedia_information_extract_relevant_context_generate_comprehensive_research_report)\n",
            "Generated TLDR: This automation workflow processes user queries to generate search queries, extract relevant information, and create a comprehensive research report.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'chat_message_trigger_generate_search_queries_agent_fetch_wikipedia_information_extract_relevant_context_generate_comprehensive_research_report'.\n",
            "\n",
            "Processing file: ðŸ‹ðŸ¤– DeepSeek AI Agent + Telegram + LONG TERM Memory ðŸ§ .txt\n",
            "Generated title: deepseek_ai_agent_telegram_long_term_memory (vector base ID: deepseek_ai_agent_telegram_long_term_memory)\n",
            "Generated TLDR: This automation workflow processes text messages from Telegram users and utilizes an AI assistant to provide personalized and engaging interactions while managing and storing memories for future use.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'deepseek_ai_agent_telegram_long_term_memory'.\n",
            "\n",
            "Processing file: Email Summary Agent.txt\n",
            "Generated title: email_summary_agent (vector base ID: email_summary_agent)\n",
            "Generated TLDR: This automation workflow fetches and summarizes emails received in the past 24 hours, then sends a styled HTML email report to recipients.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'email_summary_agent'.\n",
            "\n",
            "Processing file: Slack slash commands AI Chat Bot.txt\n",
            "Generated title: create_ai_messages_slack (vector base ID: create_ai_messages_slack)\n",
            "Generated TLDR: This automation workflow creates an AI chatbot that responds to Slack slash commands.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'create_ai_messages_slack'.\n",
            "\n",
            "Processing file: Create a Branded AI-Powered Website Chatbot.txt\n",
            "Generated title: ai_agent_chat_workflow (vector base ID: ai_agent_chat_workflow)\n",
            "Generated TLDR: This automation workflow manages appointment booking and communication through a chatbot interface.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chat_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'ai_agent_chat_workflow_1'.\n",
            "Batch 54 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 55/59 ---\n",
            "\n",
            "Processing file: RAG_Context-Aware Chunking _ Google Drive to Pinecone via OpenRouter & Gemini.txt\n",
            "Generated title: rag_context_aware_chunking_google_drive_pinecone_openrouter_gemini (vector base ID: rag_context_aware_chunking_google_drive_pinecone_openrouter_gemini)\n",
            "Generated TLDR: Converts text data from a Google document into vectors using Google Gemini and stores them in the Pinecone vector database.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'rag_context_aware_chunking_google_drive_pinecone_openrouter_gemini'.\n",
            "\n",
            "Processing file: HR & IT Helpdesk Chatbot with Audio Transcription.txt\n",
            "Generated title: hr_it_helpdesk_chatbot_with_audio_transcription (vector base ID: hr_it_helpdesk_chatbot_with_audio_transcription)\n",
            "Generated TLDR: This automation workflow creates an HR and IT helpdesk chatbot with audio transcription capabilities.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'hr_it_helpdesk_chatbot_with_audio_transcription'.\n",
            "\n",
            "Processing file: Effortless Email Management with AI-Powered Summarization & Review.txt\n",
            "Generated title: email_management_with_nlp_workflow (vector base ID: email_management_with_nlp_workflow)\n",
            "Generated TLDR: This automation workflow handles incoming emails, summarizes their content, generates appropriate responses using AI, and obtains approval before sending replies.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'email_management_with_nlp_workflow'.\n",
            "\n",
            "Processing file: AI Automated HR Workflow for CV Analysis and Candidate Evaluation.txt\n",
            "Generated title: hr_automation_pipeline_with_ai (vector base ID: hr_automation_pipeline_with_ai)\n",
            "Generated TLDR: This automation workflow automates job application handling by extracting information from CVs, analyzing candidate qualifications against a predefined profile, and storing results in a Google Sheet.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'hr_automation_pipeline_with_ai'.\n",
            "\n",
            "Processing file: AI-powered email processing autoresponder and response approval (Yes_No).txt\n",
            "Generated title: email_processing_autoreply_approval_workflow (vector base ID: email_processing_autoreply_approval_workflow)\n",
            "Generated TLDR: Automated email processing workflow with AI summarization, response generation, and approval functionality.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'email_processing_autoreply_approval_workflow'.\n",
            "Batch 55 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 56/59 ---\n",
            "\n",
            "Processing file: Social Media Analysis and Automated Email Generation.txt\n",
            "Generated title: social_media_analysis_and_automated_email_generation (vector base ID: social_media_analysis_and_automated_email_generation)\n",
            "Generated TLDR: This automation workflow analyzes social media profiles of potential leads and automatically generates personalized emails based on the analysis.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'social_media_analysis_and_automated_email_generation'.\n",
            "\n",
            "Processing file: Scrape Trustpilot Reviews with DeepSeek, Analyze Sentiment with OpenAI.txt\n",
            "Generated title: scrape_trustpilot_reviews_deepseek_openai (vector base ID: scrape_trustpilot_reviews_deepseek_openai)\n",
            "Generated TLDR: This automation workflow scrapes Trustpilot reviews with DeepSeek, analyzes sentiment with OpenAI, and saves the extracted information to Google Drive.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'scrape_trustpilot_reviews_deepseek_openai'.\n",
            "\n",
            "Processing file: Chat with Postgresql Database.txt\n",
            "Generated title: ai_agent_database_interaction (vector base ID: ai_agent_database_interaction)\n",
            "Generated TLDR: This automation enables users to chat with a PostgreSQL database using AI agents for query execution and data analysis.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_database_interaction'.\n",
            "\n",
            "Processing file: AI Voice Chatbot with ElevenLabs & OpenAI for Customer Service and Restaurants.txt\n",
            "Generated title: voice_chatbot_qdrant_openai_elevenlabs_workflow (vector base ID: voice_chatbot_qdrant_openai_elevenlabs_workflow)\n",
            "Generated TLDR: This automation workflow creates a voice chatbot that interacts with chat agents using AI technology.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'voice_chatbot_qdrant_openai_elevenlabs_workflow'.\n",
            "\n",
            "Processing file: AI-Powered Email Automation for Business_ Summarize & Respond with RAG.txt\n",
            "Generated title: email_ai_auto_responder_summarizer_workflow (vector base ID: email_ai_auto_responder_summarizer_workflow)\n",
            "Generated TLDR: This automation workflow summarizes and sends replies to emails using AI, classifies emails, summarizes content, and sends structured responses.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'email_ai_auto_responder_summarizer_workflow_0'.\n",
            "Upserted chunk 1 as vector ID 'email_ai_auto_responder_summarizer_workflow_1'.\n",
            "Batch 56 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 57/59 ---\n",
            "\n",
            "Processing file: Upload to Instagram and Tiktok from Google Drive.txt\n",
            "Generated title: upload_video_description_google_drive_tiktok_instagram (vector base ID: upload_video_description_google_drive_tiktok_instagram)\n",
            "Generated TLDR: This automation uploads videos to Google Drive, extracts audio for descriptions, generates descriptions with AI, and uploads the videos and descriptions to Tiktok and Instagram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'upload_video_description_google_drive_tiktok_instagram'.\n",
            "\n",
            "Processing file: Automate Pinterest Analysis & AI-Powered Content Suggestions With Pinterest API.txt\n",
            "Generated title: automate_pinterest_analysis_ai_content_suggestions (vector base ID: automate_pinterest_analysis_ai_content_suggestions)\n",
            "Generated TLDR: This automation workflow gathers Pinterest Pin data, analyzes trends with AI, summarizes the results, and sends suggestions to the Marketing Manager via email.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automate_pinterest_analysis_ai_content_suggestions'.\n",
            "\n",
            "Processing file: Build an OpenAI Assistant with Google Drive Integration.txt\n",
            "Generated title: build_openai_assistant_google_drive_integration (vector base ID: build_openai_assistant_google_drive_integration)\n",
            "Generated TLDR: This automation workflow creates an OpenAI assistant for a travel agency and integrates it with Google Drive for file updates and chat interactions.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'build_openai_assistant_google_drive_integration'.\n",
            "\n",
            "Processing file: ðŸ”ðŸ¦™ðŸ¤– Private & Local Ollama Self-Hosted AI Assistant.txt\n",
            "Generated title: ollama_chat_workflow (vector base ID: ollama_chat_workflow)\n",
            "Generated TLDR: This automation workflow processes chat messages using the Ollama LLM model and returns structured JSON responses.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ollama_chat_workflow'.\n",
            "\n",
            "Processing file: Auto-Tag Blog Posts in WordPress with AI.txt\n",
            "Generated title: auto_tag_posts_in_wordpress (vector base ID: auto_tag_posts_in_wordpress)\n",
            "Generated TLDR: Automatically tags blog posts in WordPress using AI, eliminating the need for manual data entry.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'auto_tag_posts_in_wordpress'.\n",
            "Batch 57 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 58/59 ---\n",
            "\n",
            "Processing file: Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46714 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46714 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46714 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46714 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_title: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46714 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using fallback title: Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt (vector base ID: Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt)\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46678 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46678 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46678 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46678 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Retrying in 2 seconds...\n",
            "Error calling _generate_tldr: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 46678 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
            "Max retries reached.\n",
            "Using empty TLDR.\n",
            "Processing 8 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_0'.\n",
            "Upserted chunk 1 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_1'.\n",
            "Upserted chunk 2 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_2'.\n",
            "Upserted chunk 3 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_3'.\n",
            "Upserted chunk 4 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_4'.\n",
            "Upserted chunk 5 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_5'.\n",
            "Upserted chunk 6 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_6'.\n",
            "Upserted chunk 7 as vector ID 'Host Your Own AI Deep Research Agent with n8n, Apify and OpenAI o3.txt_7'.\n",
            "\n",
            "Processing file: Proxmox AI Agent with n8n and Generative AI Integration.txt\n",
            "Generated title: proxmox_custom_ai_agent (vector base ID: proxmox_custom_ai_agent)\n",
            "Generated TLDR: This automation workflow interacts with the Proxmox API to perform CRUD operations based on user commands.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'proxmox_custom_ai_agent_0'.\n",
            "Upserted chunk 1 as vector ID 'proxmox_custom_ai_agent_1'.\n",
            "\n",
            "Processing file: Automate Content Generator for WordPress with DeepSeek R1.txt\n",
            "Generated title: automate_content_generator_wordpress_deepseek (vector base ID: automate_content_generator_wordpress_deepseek)\n",
            "Generated TLDR: Automatically generates SEO-friendly content for WordPress by using input ideas to structure articles and creating cover images with DeepSeek and OpenAI.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'automate_content_generator_wordpress_deepseek'.\n",
            "\n",
            "Processing file: A Very Simple _Human in the Loop_ Email Response System Using AI and IMAP.txt\n",
            "Generated title: email_trigger_imap_email_summarization_openai_reply_agent (vector base ID: email_trigger_imap_email_summarization_openai_reply_agent)\n",
            "Generated TLDR: This automation workflow automates email handling, summarization, response generation, and validation through a \"Human in the loop\" system.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'email_trigger_imap_email_summarization_openai_reply_agent'.\n",
            "\n",
            "Processing file: ðŸ¤–ðŸ§  AI Agent Chatbot + LONG TERM Memory + Note Storage + Telegram.txt\n",
            "Generated title: ai_agent_chatbot_long_term_memory_note_storage_telegram (vector base ID: ai_agent_chatbot_long_term_memory_note_storage_telegram)\n",
            "Generated TLDR: This automation workflow creates an AI chatbot with long-term memory and note storage capabilities using Google Docs and Telegram.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chatbot_long_term_memory_note_storage_telegram'.\n",
            "Batch 58 complete. Pausing for 10 seconds before next batch...\n",
            "\n",
            "--- Processing Batch 59/59 ---\n",
            "\n",
            "Processing file: Generate Instagram Content from Top Trends with AI Image Generation.txt\n",
            "Generated title: generate_instagram_content_from_top_trends_with_ai_image_generation (vector base ID: generate_instagram_content_from_top_trends_with_ai_image_generation)\n",
            "Generated TLDR: Automated workflow: Scrapes top trending Instagram posts, generates AI captions & images, and auto-posts content to Instagram.\n",
            "Processing 2 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'generate_instagram_content_from_top_trends_with_ai_image_generation_0'.\n",
            "Upserted chunk 1 as vector ID 'generate_instagram_content_from_top_trends_with_ai_image_generation_1'.\n",
            "\n",
            "Processing file: Simple Expense Tracker with n8n Chat, AI Agent and Google Sheets.txt\n",
            "Generated title: agent_google_sheet_expense_tracker (vector base ID: agent_google_sheet_expense_tracker)\n",
            "Generated TLDR: TLDR: This automation workflow allows users to submit expenses via chat message, parses the message to structured JSON, and saves it as a new row in Google Sheets.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'agent_google_sheet_expense_tracker'.\n",
            "\n",
            "Processing file: Automate SIEM Alert Enrichment with MITRE ATT&CK, Qdrant & Zendesk in n8n.txt\n",
            "Generated title: ai_agent_chat_interaction_with_mitre_data_processing (vector base ID: ai_agent_chat_interaction_with_mitre_data_processing)\n",
            "Generated TLDR: This automation workflow uses AI to extract and analyze cybersecurity data from SIEM alerts, provide actionable remediation steps, and update Zendesk tickets with MITRE ATT&CK information.\n",
            "Processing 1 chunk(s).\n",
            "Upserted chunk 0 as vector ID 'ai_agent_chat_interaction_with_mitre_data_processing'.\n",
            "\n",
            "All files processed successfully!\n"
          ]
        }
      ]
    }
  ]
}